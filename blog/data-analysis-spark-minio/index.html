<!doctype html><html lang=en-us>
<head>
<meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge,chrome=1">
<title>Prashant's Scrapbook | Data Analysis using Sparks, Pandas, and Matplotlib using Jupyter Notebook for data in S3(Minio)</title>
<meta name=viewport content="width=device-width,minimum-scale=1">
<meta name=generator content="Hugo 0.91.2">
<meta name=ROBOTS content="INDEX, FOLLOW">
<link href=/dist/css/app.1cb140d8ba31d5b2f1114537dd04802a.css rel=stylesheet>
<meta property="og:title" content="Data Analysis using Sparks, Pandas, and Matplotlib using Jupyter Notebook for data in S3(Minio)">
<meta property="og:description" content="Data Analysis is to understand problems facing an organization and to explore data in meaningful ways. Data in itself is merely facts and figures. Evaluation of the data can provide advantages to the organization and aid in making business decisions.
Brief Overview of the components Apache Spark is a lightning-fast cluster computing technology, designed for fast computation and based on Hadoop MapReduce.
Pandas is a software library written in Python for data manipulation and analysis.">
<meta property="og:type" content="article">
<meta property="og:url" content="https://prashantshahi.dev/blog/data-analysis-spark-minio/"><meta property="article:section" content="blog">
<meta property="article:published_time" content="2019-05-13T08:30:00+05:30">
<meta property="article:modified_time" content="2019-05-13T08:30:00+05:30">
<meta itemprop=name content="Data Analysis using Sparks, Pandas, and Matplotlib using Jupyter Notebook for data in S3(Minio)">
<meta itemprop=description content="Data Analysis is to understand problems facing an organization and to explore data in meaningful ways. Data in itself is merely facts and figures. Evaluation of the data can provide advantages to the organization and aid in making business decisions.
Brief Overview of the components Apache Spark is a lightning-fast cluster computing technology, designed for fast computation and based on Hadoop MapReduce.
Pandas is a software library written in Python for data manipulation and analysis."><meta itemprop=datePublished content="2019-05-13T08:30:00+05:30">
<meta itemprop=dateModified content="2019-05-13T08:30:00+05:30">
<meta itemprop=wordCount content="2709">
<meta itemprop=keywords content="apache spark,big data,data analysis,jupyter notebook,minio,pandas,"><meta name=twitter:card content="summary">
<meta name=twitter:title content="Data Analysis using Sparks, Pandas, and Matplotlib using Jupyter Notebook for data in S3(Minio)">
<meta name=twitter:description content="Data Analysis is to understand problems facing an organization and to explore data in meaningful ways. Data in itself is merely facts and figures. Evaluation of the data can provide advantages to the organization and aid in making business decisions.
Brief Overview of the components Apache Spark is a lightning-fast cluster computing technology, designed for fast computation and based on Hadoop MapReduce.
Pandas is a software library written in Python for data manipulation and analysis.">
<script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga('create','UA-116535819-4','auto'),ga('send','pageview'))</script>
<script async src=https://www.google-analytics.com/analytics.js></script>
</head>
<body class="ma0 avenir bg-near-white">
<header>
<div class=bg-black>
<nav class="pv3 ph3 ph4-ns" role=navigation>
<div class="flex-l justify-between items-center center">
<a href=https://prashantshahi.dev/ class="f3 fw2 hover-white no-underline white-90 dib">
Prashant's Scrapbook
</a>
<div class="flex-l items-center">
<ul class="pl0 mr3">
<li class="list f5 f4-ns fw4 dib pr3">
<a class="hover-white no-underline white-90" href=/ title="Home page">
Home
</a>
</li>
<li class="list f5 f4-ns fw4 dib pr3">
<a class="hover-white no-underline white-90" href=/blog title="Blog page">
Blog
</a>
</li>
<li class="list f5 f4-ns fw4 dib pr3">
<a class="hover-white no-underline white-90" href=/#about title="About page">
About
</a>
</li>
<li class="list f5 f4-ns fw4 dib pr3">
<a class="hover-white no-underline white-90" href=/#work title="Work page">
Work
</a>
</li>
</ul>
</div>
</div>
</nav>
</div>
</header>
<main class=pb5 role=main>
<article class="flex-l flex-wrap justify-between mw8 center ph3">
<header class="mt4 w-100">
<aside class="instapaper_ignoref b helvetica tracked">
BLOG
</aside>
<div id=sharing class=mt3>
<a href="https://www.facebook.com/sharer.php?u=https://prashantshahi.dev/blog/data-analysis-spark-minio/" class="facebook no-underline" aria-label="share on Facebook"><svg height="32" style="enable-background:new 0 0 67 67" viewBox="0 0 67 67" width="32" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M28.765 50.32h6.744V33.998h4.499l.596-5.624h-5.095l.007-2.816c0-1.466.14-2.253 2.244-2.253h2.812V17.68h-4.5c-5.405.0-7.307 2.729-7.307 7.317v3.377h-3.369v5.625h3.369V50.32zM33 64C16.432 64 3 50.569 3 34S16.432 4 33 4s30 13.431 30 30S49.568 64 33 64z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg>
</a>
<a href="https://twitter.com/share?url=https://prashantshahi.dev/blog/data-analysis-spark-minio/&text=Data%20Analysis%20using%20Sparks,%20Pandas,%20and%20Matplotlib%20using%20Jupyter%20Notebook%20for%20data%20in%20S3%28Minio%29" class="twitter no-underline" aria-label="share on Twitter"><svg height="32" style="enable-background:new 0 0 67 67" viewBox="0 0 67 67" width="32" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M37.167 22.283c-2.619.953-4.274 3.411-4.086 6.101l.063 1.038-1.048-.127c-3.813-.487-7.145-2.139-9.974-4.915l-1.383-1.377-.356 1.017c-.754 2.267-.272 4.661 1.299 6.271.838.89.649 1.017-.796.487-.503-.169-.943-.296-.985-.233-.146.149.356 2.076.754 2.839.545 1.06 1.655 2.097 2.871 2.712l1.027.487-1.215.021c-1.173.0-1.215.021-1.089.467.419 1.377 2.074 2.839 3.918 3.475l1.299.444-1.131.678c-1.676.976-3.646 1.526-5.616 1.568C19.775 43.256 19 43.341 19 43.405c0 .211 2.557 1.397 4.044 1.864 4.463 1.377 9.765.783 13.746-1.568 2.829-1.673 5.657-5 6.978-8.221.713-1.716 1.425-4.851 1.425-6.354.0-.975.063-1.102 1.236-2.267.692-.678 1.341-1.419 1.467-1.631.21-.403.188-.403-.88-.043-1.781.636-2.033.551-1.152-.402.649-.678 1.425-1.907 1.425-2.267.0-.063-.314.042-.671.233-.377.212-1.215.53-1.844.72l-1.131.361-1.027-.7c-.566-.381-1.361-.805-1.781-.932C39.766 21.902 38.131 21.944 37.167 22.283zM33 64C16.432 64 3 50.569 3 34S16.432 4 33 4s30 13.431 30 30S49.568 64 33 64z" style="fill-rule:evenodd;clip-rule:evenodd;fill:"/></svg>
</a>
<a href="https://www.linkedin.com/shareArticle?mini=true&url=https://prashantshahi.dev/blog/data-analysis-spark-minio/&title=Data%20Analysis%20using%20Sparks,%20Pandas,%20and%20Matplotlib%20using%20Jupyter%20Notebook%20for%20data%20in%20S3%28Minio%29" class="linkedin no-underline" aria-label="share on LinkedIn"><svg height="32" style="enable-background:new 0 0 65 65" viewBox="0 0 65 65" width="32" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M50.837 48.137V36.425c0-6.275-3.35-9.195-7.816-9.195-3.604.0-5.219 1.983-6.119 3.374V27.71h-6.79c.09 1.917.0 20.427.0 20.427h6.79V36.729c0-.609.044-1.219.224-1.655.49-1.22 1.607-2.483 3.482-2.483 2.458.0 3.44 1.873 3.44 4.618v10.929H50.837zM22.959 24.922c2.367.0 3.842-1.57 3.842-3.531-.044-2.003-1.475-3.528-3.797-3.528s-3.841 1.524-3.841 3.528c0 1.961 1.474 3.531 3.753 3.531H22.959zM34 64C17.432 64 4 50.568 4 34 4 17.431 17.432 4 34 4s30 13.431 30 30c0 16.568-13.432 30-30 30zM26.354 48.137V27.71h-6.789v20.427h6.789z" style="fill-rule:evenodd;clip-rule:evenodd;fill:"/></svg>
</a>
</div>
<h1 class="f1 athelas mt3 mb1">Data Analysis using Sparks, Pandas, and Matplotlib using Jupyter Notebook for data in S3(Minio)</h1>
<p class=tracked>
By <strong>
Prashant Shahi
</strong>
</p>
<time class="f6 mv4 dib tracked" datetime=2019-05-13T08:30:00+05:30>May 13, 2019</time>
<span class="f6 mv4 dib tracked"> - 13 minutes read</span>
<span class="f6 mv4 dib tracked"> - 2709 words</span>
</header>
<div class="nested-copy-line-height lh-copy serif f4 nested-links nested-img mid-gray pr4-l w-two-thirds-l"><p><strong>Data Analysis</strong> is to understand problems facing an organization and to explore data in
meaningful ways. Data in itself is merely facts and figures. Evaluation of the data can
provide advantages to the organization and aid in making business decisions.</p>
<h2 id=brief-overview-of-the-components>Brief Overview of the components</h2>
<p><strong>Apache Spark</strong> is a lightning-fast cluster computing technology, designed for fast
computation and based on Hadoop MapReduce.</p>
<p><strong>Pandas</strong> is a software library written in Python for data manipulation and analysis.
Similarly, <strong>Matplotlib</strong> is another python library used for 2D plotting which produces
publication quality figures in a variety of hardcopy formats and interactive
environments across platforms.</p>
<p><strong>Jupyter Notebook</strong> is an open-source web application that allows you to create and
share documents that contain live code, equations, visualizations, and narrative text. </p>
<p><strong>Minio</strong> is an open-source cloud object storage server which follows Amazon S3 protocol
and at times, referred to as an Open-Source Amazon S3 alternative, which is available for
anyone on internet for free to deploy on their machines.</p>
<h2 id=setup>Setup</h2>
<h3 id=system-configuration-vminstance>System configuration (VM/Instance)</h3>
<p>The system configuration selected for the task is as mentioned below :</p>
<ul>
<li>6 cores CPUs</li>
<li>10 GB memory (RAM)</li>
<li>200 GB Disk Size (ROM)</li>
</ul>
<p>It should be fine even if your machine configurations are lower the one used here.</p>
<h3 id=downloading-minio-server-andclient>Downloading Minio Server and Client</h3>
<p><strong>Minio Server</strong></p>
<p>Follow the steps below to setup Minio Server : </p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=color:#75715e># Downloading Minio binary and copying to /opt</span>
sudo wget -O /opt/minio https://dl.minio.io/server/minio/release/linux-amd64/minio
<span style=color:#75715e># Changing the file permission of binary to mark as executable</span>
sudo chmod +x /opt/minio
<span style=color:#75715e># Creating a symbolic link to /usr/local/bin to make the file executable from any path</span>
sudo ln -s /opt/minio /usr/local/bin/
<span style=color:#75715e># Making the data directory for storing the objects/data for minio server</span>
mkdir ./data
<span style=color:#75715e># Running the Minio server with the data directory parameter</span>
minio server ./data
</code></pre></div><h3 id=minio-client>Minio Client</h3>
<p>Follow the steps below to setup Minio Client :</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=color:#75715e># Downloading minio binary and copying to /opt</span>
sudo wget -O /opt/mc https://dl.minio.io/client/mc/release/linux-amd64/mc
<span style=color:#75715e># Changing the file permission of binary to mark as executable</span>
sudo chmod +x /opt/mc
<span style=color:#75715e># Creatin a symbolic link to /usr/local/bin to make the file executable from any path</span>
sudo ln -s /opt/mc /usr/local/bin
<span style=color:#75715e># Executing the command with help parameter to ensure that installation was a success</span>
mc --help
</code></pre></div><h3 id=loading-sampledata>Loading Sample Data</h3>
<p>Follow the steps below how to load a Sample Data to S3 using Minio Client :</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=color:#75715e># Downloading the sample data of TotalPopulationBySex.csv from UN</span>
wget -O TotalPopulation.csv <span style=color:#e6db74>&#34;https://esa.un.org/unpd/wpp/DVD/Files/1_Indicators%20(Standard)/CSV_FILES/WPP2017_TotalPopulationBySex.csv&#34;</span>
<span style=color:#75715e># Compressing the csv file</span>
gzip TotalPopulation.csv
<span style=color:#75715e># Creating a new bucket</span>
mc mb data/mycsvbucket
<span style=color:#75715e># Copying the compressed file inside bucket</span>
mc cp TotalPopulation.csv.gz data/mycsvbucket/
</code></pre></div><h3 id=setting-up-java-environment-for-sparkshell>Setting up Java Environment for Spark Shell</h3>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=color:#75715e># Adding ppa to local repository</span>
sudo add-apt-repository ppa:webupd8team/java
<span style=color:#75715e># Updating repository archives</span>
sudo apt update
<span style=color:#75715e># Installing Oracle Java8</span>
sudo apt install -y oracle-java8-installer
<span style=color:#75715e># Verifying the java installation</span>
javac -version
<span style=color:#75715e># Setting Oracle Java8 as default (In case of multiple java versions)</span>
sudo apt install -y oracle-java8-set-default
<span style=color:#75715e># Setting up environment variable (Also, add this to the `~/.bashrc` file to apply for next boot)</span>
export JAVA_HOME<span style=color:#f92672>=</span>/usr/lib/jvm/java-8-oracle
export PATH<span style=color:#f92672>=</span>$PATH:$JAVA_HOME/bin
</code></pre></div><h3 id=installation-of-apache-spark-andhadoop>Installation of Apache Spark and Hadoop</h3>
<p>Steps to install Apache Spark is as follow :</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=color:#75715e># Download Spark v2.3.0 without Hadoop</span>
wget http://archive.apache.org/dist/spark/spark-2.3.0/spark-2.3.0-bin-without-hadoop.tgz
<span style=color:#75715e># Extracting the compressed file</span>
sudo tar -C /opt/ -xvf spark-2.3.0-bin-without-hadoop.tgz
<span style=color:#75715e># Setting up environment variable (Also, add this to the `~/.bashrc` file to apply for next boot)</span>
export SPARK_HOME<span style=color:#f92672>=</span>/opt/spark-2.3.0-bin-without-hadoop
export PATH<span style=color:#f92672>=</span>$PATH:$SPARK_HOME/bin
</code></pre></div><p>Steps to install Apache Hadoop is as follow :</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=color:#75715e># Download Hadoop v2.8.2</span>
wget https://archive.apache.org/dist/hadoop/core/hadoop-2.8.2/hadoop-2.8.2.tar.gz
<span style=color:#75715e># Extracting the compressed file</span>
sudo tar -C /opt/ -xvf hadoop-2.8.2.tar.gz
<span style=color:#75715e># Setting up environment for Hadoop</span>
export HADOOP_HOME<span style=color:#f92672>=</span>/opt/hadoop-2.8.2
export PATH<span style=color:#f92672>=</span>$PATH:$HADOOP_HOME/bin
export SPARK_DIST_CLASSPATH<span style=color:#f92672>=</span><span style=color:#66d9ef>$(</span>hadoop classpath<span style=color:#66d9ef>)</span>
export LD_LIBRARY_PATH<span style=color:#f92672>=</span>$HADOOP_HOME/lib/native
</code></pre></div><h3 id=setting-up-minio-server-endpoint-and-credentials>Setting up Minio Server endpoint and credentials</h3>
<p>Open the file $HADOOP_HOME/etc/hadoop/core-site.xml for editing.
In the example XML file below, Minio server is running at http://127.0.0.1:9000
with access key minio and secret key minio123. Make sure to update relevant sections
with valid Minio server endpoint and credentials.</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-xml data-lang=xml><span style=color:#75715e>&lt;?xml version=&#34;1.0&#34; encoding=&#34;UTF-8&#34;?&gt;</span>
<span style=color:#75715e>&lt;?xml-stylesheet type=&#34;text/xsl&#34; href=&#34;configuration.xsl&#34;?&gt;</span>

<span style=color:#f92672>&lt;configuration&gt;</span>
  <span style=color:#f92672>&lt;property&gt;</span>
    <span style=color:#f92672>&lt;name&gt;</span>fs.s3a.endpoint<span style=color:#f92672>&lt;/name&gt;</span>
    <span style=color:#f92672>&lt;description&gt;</span>AWS S3 endpoint to connect to. An up-to-date list is
      provided in the AWS Documentation: regions and endpoints. Without this
      property, the standard region (s3.amazonaws.com) is assumed.
    <span style=color:#f92672>&lt;/description&gt;</span>
    <span style=color:#f92672>&lt;value&gt;</span>http://127.0.0.1:9000<span style=color:#f92672>&lt;/value&gt;</span>
  <span style=color:#f92672>&lt;/property&gt;</span>

  <span style=color:#f92672>&lt;property&gt;</span>
    <span style=color:#f92672>&lt;name&gt;</span>fs.s3a.access.key<span style=color:#f92672>&lt;/name&gt;</span>
    <span style=color:#f92672>&lt;description&gt;</span>AWS access key ID.<span style=color:#f92672>&lt;/description&gt;</span>
    <span style=color:#f92672>&lt;value&gt;</span>minio<span style=color:#f92672>&lt;/value&gt;</span>
  <span style=color:#f92672>&lt;/property&gt;</span>

  <span style=color:#f92672>&lt;property&gt;</span>
    <span style=color:#f92672>&lt;name&gt;</span>fs.s3a.secret.key<span style=color:#f92672>&lt;/name&gt;</span>
    <span style=color:#f92672>&lt;description&gt;</span>AWS secret key.<span style=color:#f92672>&lt;/description&gt;</span>
    <span style=color:#f92672>&lt;value&gt;</span>minio123<span style=color:#f92672>&lt;/value&gt;</span>
  <span style=color:#f92672>&lt;/property&gt;</span>

  <span style=color:#f92672>&lt;property&gt;</span>
    <span style=color:#f92672>&lt;name&gt;</span>fs.s3a.path.style.access<span style=color:#f92672>&lt;/name&gt;</span>
    <span style=color:#f92672>&lt;value&gt;</span>true<span style=color:#f92672>&lt;/value&gt;</span>
    <span style=color:#f92672>&lt;description&gt;</span>Enable S3 path style access ie disabling the default virtual hosting behaviour.
      Useful for S3A-compliant storage providers as it removes the need to set up DNS for virtual hosting.
    <span style=color:#f92672>&lt;/description&gt;</span>
  <span style=color:#f92672>&lt;/property&gt;</span>

  <span style=color:#f92672>&lt;property&gt;</span>
    <span style=color:#f92672>&lt;name&gt;</span>fs.s3a.impl<span style=color:#f92672>&lt;/name&gt;</span>
    <span style=color:#f92672>&lt;value&gt;</span>org.apache.hadoop.fs.s3a.S3AFileSystem<span style=color:#f92672>&lt;/value&gt;</span>
    <span style=color:#f92672>&lt;description&gt;</span>The implementation class of the S3A Filesystem<span style=color:#f92672>&lt;/description&gt;</span>
  <span style=color:#f92672>&lt;/property&gt;</span>
<span style=color:#f92672>&lt;/configuration&gt;</span>
</code></pre></div><h2 id=get-started>Get started</h2>
<h3 id=spark-shell-on-csv-in-minios3>Spark Shell on CSV in Minio (S3)</h3>
<p><em>Note: Make sure JAVA_HOME has been set before setting up Spark Shell.</em></p>
<p><strong>Spark-Select</strong> can be integrated with Spark via <code>spark-shell</code>, <code>pyspark</code>, <code>spark-submit</code>, etc. You can also add it as Maven dependency, sbt-spark-package or a jar import.</p>
<p>Let&rsquo;s go through the steps below to use <code>spark-shell</code> in an example.</p>
<ul>
<li>
<p>Start Minio server and configure mc to interact with this server.</p>
</li>
<li>
<p>Create a bucket and upload a sample file : </p>
</li>
</ul>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=color:#75715e># Downloading sample csv</span>
wget <span style=color:#e6db74>&#34;https://gist.github.com/raw/dc0d42feb6e8c816ed2ff1778b35a130/people.csv&#34;</span>
<span style=color:#75715e># Creating a bucket named sjm-airlines</span>
mc mb data/sjm-airlines
<span style=color:#75715e># Copying the csv to the created bucket using minio client</span>
mc cp people.csv data/sjm-airlines
</code></pre></div><ul>
<li>Download the sample scala code: </li>
</ul>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh>wget <span style=color:#e6db74>&#34;https://gist.github.com/raw/dc0d42feb6e8c816ed2ff1778b35a130/csv.scala&#34;</span>
</code></pre></div><ul>
<li>Downloading depedencies and adding it to spark : </li>
</ul>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=color:#75715e># Creating jars folder</span>
mkdir jars
<span style=color:#75715e># Changing current directory to ./jars</span>
cd jars
<span style=color:#75715e># Downloading jar dependencies</span>
wget http://central.maven.org/maven2/org/apache/hadoop/hadoop-aws/2.8.2/hadoop-aws-2.8.2.jar
wget http://central.maven.org/maven2/org/apache/httpcomponents/httpclient/4.5.3/httpclient-4.5.3.jar
wget http://central.maven.org/maven2/joda-time/joda-time/2.9.9/joda-time-2.9.9.jar
wget http://central.maven.org/maven2/com/amazonaws/aws-java-sdk-s3/1.11.524/aws-java-sdk-s3-1.11.524.jar
wget http://central.maven.org/maven2/com/amazonaws/aws-java-sdk-core/1.11.524/aws-java-sdk-core-1.11.524.jar
wget http://central.maven.org/maven2/com/amazonaws/aws-java-sdk/1.11.524/aws-java-sdk-1.11.524.jar
wget http://central.maven.org/maven2/com/amazonaws/aws-java-sdk-kms/1.11.524/aws-java-sdk-kms-1.11.524.jar
<span style=color:#75715e># Copying all the jars to $SPARK_HOME/jars/</span>
cp *.jar $SPARK_HOME/jars/
</code></pre></div><ul>
<li>
<p>Configure Apache Spark with Minio. Detailed steps are available in <a href=https://github.com/minio/cookbook/blob/master/docs/apache-spark-with-minio.md>this document</a>.</p>
</li>
<li>
<p>Let&rsquo;s start <code>spark-shell</code> with the following command. To load some additional package later on, you can use <code>--packages</code> flag as well. </p>
</li>
</ul>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh>$SPARK_HOME/bin/spark-shell --master local<span style=color:#f92672>[</span>4<span style=color:#f92672>]</span>
</code></pre></div><ul>
<li>After <code>spark-shell</code> is successfully invoked, load the <em>csv.scala</em>, and display the data:</li>
</ul>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-scala data-lang=scala><span style=color:#a6e22e>Welcome</span> to
      <span style=color:#a6e22e>____</span>              <span style=color:#a6e22e>__</span>
     <span style=color:#f92672>/</span> <span style=color:#a6e22e>__/__</span>  <span style=color:#a6e22e>___</span> <span style=color:#a6e22e>_____</span><span style=color:#f92672>/</span> <span style=color:#f92672>/</span><span style=color:#a6e22e>__</span>
    <span style=color:#66d9ef>_</span>\ \<span style=color:#f92672>/</span> <span style=color:#66d9ef>_</span> \<span style=color:#f92672>/</span> <span style=color:#66d9ef>_</span> <span style=color:#960050;background-color:#1e0010>`</span><span style=color:#f92672>/</span> <span style=color:#a6e22e>__</span><span style=color:#f92672>/</span>  &#39;_/
   <span style=color:#f92672>/</span><span style=color:#a6e22e>___</span><span style=color:#f92672>/</span> <span style=color:#f92672>.</span><span style=color:#a6e22e>__/\</span><span style=color:#66d9ef>_</span><span style=color:#f92672>,</span><span style=color:#66d9ef>_</span><span style=color:#f92672>/</span><span style=color:#66d9ef>_</span><span style=color:#f92672>/</span> <span style=color:#f92672>/</span><span style=color:#66d9ef>_</span><span style=color:#f92672>/\</span><span style=color:#66d9ef>_</span>\   version <span style=color:#ae81ff>2.3</span><span style=color:#f92672>.</span><span style=color:#ae81ff>0</span>
      <span style=color:#f92672>/</span><span style=color:#66d9ef>_</span><span style=color:#f92672>/</span>

<span style=color:#a6e22e>Using</span> <span style=color:#a6e22e>Scala</span> version <span style=color:#ae81ff>2.</span><span style=color:#a6e22e>XX</span><span style=color:#f92672>.</span><span style=color:#a6e22e>XX</span> <span style=color:#f92672>(</span><span style=color:#a6e22e>Java</span> <span style=color:#a6e22e>HotSpot</span><span style=color:#f92672>(</span><span style=color:#a6e22e>TM</span><span style=color:#f92672>)</span> <span style=color:#ae81ff>64</span><span style=color:#f92672>-</span><span style=color:#a6e22e>Bit</span> <span style=color:#a6e22e>Server</span> <span style=color:#a6e22e>VM</span><span style=color:#f92672>,</span> <span style=color:#a6e22e>Java</span> <span style=color:#ae81ff>1.8</span><span style=color:#f92672>.</span><span style=color:#ae81ff>0</span><span style=color:#a6e22e>_XXX</span><span style=color:#f92672>)</span>
<span style=color:#a6e22e>Type</span> in expressions to have them evaluated<span style=color:#f92672>.</span>
<span style=color:#a6e22e>Type</span> <span style=color:#66d9ef>:</span><span style=color:#66d9ef>help</span> <span style=color:#66d9ef>for</span> <span style=color:#66d9ef>more</span> <span style=color:#66d9ef>information.</span>

<span style=color:#66d9ef>scala&gt;</span> <span style=color:#66d9ef>:load</span> <span style=color:#66d9ef>csv.scala</span>
<span style=color:#a6e22e>Loading</span> examples<span style=color:#f92672>/</span>csv<span style=color:#f92672>.</span>scala<span style=color:#f92672>...</span>
<span style=color:#66d9ef>import</span> org.apache.spark.sql._
<span style=color:#66d9ef>import</span> org.apache.spark.sql.types._
defined <span style=color:#66d9ef>object</span> <span style=color:#a6e22e>app</span>

scala<span style=color:#f92672>&gt;</span> app<span style=color:#f92672>.</span>main<span style=color:#f92672>(</span><span style=color:#a6e22e>Array</span><span style=color:#f92672>())</span>
<span style=color:#f92672>+-------+---+</span>
<span style=color:#f92672>|</span>   name<span style=color:#f92672>|</span>age<span style=color:#f92672>|</span>
<span style=color:#f92672>+-------+---+</span>
<span style=color:#f92672>|</span><span style=color:#a6e22e>Michael</span><span style=color:#f92672>|</span> <span style=color:#ae81ff>31</span><span style=color:#f92672>|</span>
<span style=color:#f92672>|</span>   <span style=color:#a6e22e>Andy</span><span style=color:#f92672>|</span> <span style=color:#ae81ff>30</span><span style=color:#f92672>|</span>
<span style=color:#f92672>|</span> <span style=color:#a6e22e>Justin</span><span style=color:#f92672>|</span> <span style=color:#ae81ff>19</span><span style=color:#f92672>|</span>
<span style=color:#f92672>+-------+---+</span>

<span style=color:#f92672>+-------+---+</span>
<span style=color:#f92672>|</span>   name<span style=color:#f92672>|</span>age<span style=color:#f92672>|</span>
<span style=color:#f92672>+-------+---+</span>
<span style=color:#f92672>|</span><span style=color:#a6e22e>Michael</span><span style=color:#f92672>|</span> <span style=color:#ae81ff>31</span><span style=color:#f92672>|</span>
<span style=color:#f92672>|</span>   <span style=color:#a6e22e>Andy</span><span style=color:#f92672>|</span> <span style=color:#ae81ff>30</span><span style=color:#f92672>|</span>
<span style=color:#f92672>+-------+---+</span>
scala<span style=color:#f92672>&gt;</span>
</code></pre></div><p><img src=/images/data-analysis/1.jpg alt="Scala UI"></p>
<p>You can see that out of 3 entries, we could use SQL-like query to only select those
entries with age > 19.</p>
<p>Awesome, you have successfully set up Spark! Let&rsquo;s proceed futher.</p>
<h3 id=spark-shell-using-pyspark-andminio>Spark-Shell using PySpark and Minio</h3>
<p>Make sure all of the <code>aws-java-sdk</code> jars are present under <code>$SPARK_HOME/jars/</code> or
added to the <code>spark.jars.packages</code> in <em>spark-defaults.conf</em> file, before proceeding.</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=color:#75715e># Running pyspark from Spark_Home Binary</span>
$SPARK_HOME/bin/pyspark
<span style=color:#e6db74>``</span>

You should see the following screen :

<span style=color:#e6db74>```</span>python
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _<span style=color:#ae81ff>\ \/</span> _ <span style=color:#ae81ff>\/</span> _ <span style=color:#e6db74>`</span>/ __/  <span style=color:#e6db74>&#39;_/
</span><span style=color:#e6db74>   /__ / .__/\_,_/_/ /_/\_\   version 2.3.0
</span><span style=color:#e6db74>      /_/
</span><span style=color:#e6db74>
</span><span style=color:#e6db74>Using Python version 2.7.12 (default, Nov 12 2018 14:36:49)
</span><span style=color:#e6db74>SparkSession available as &#39;</span>spark<span style=color:#960050;background-color:#1e0010>&#39;</span>.
&gt;&gt;&gt;
</code></pre></div><p>Let&rsquo;s execute the commands following lines to verify the same as in <code>scala-shell</code> can be achieved in <em>PySpark</em>:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>&gt;&gt;&gt;</span> <span style=color:#f92672>from</span> pyspark.sql.types <span style=color:#f92672>import</span> <span style=color:#f92672>*</span>
<span style=color:#f92672>&gt;&gt;&gt;</span> df <span style=color:#f92672>=</span> spark<span style=color:#f92672>.</span>read<span style=color:#f92672>.</span>format(<span style=color:#e6db74>&#34;csv&#34;</span>)<span style=color:#f92672>.</span>option(<span style=color:#e6db74>&#34;header&#34;</span>, <span style=color:#e6db74>&#34;true&#34;</span>)<span style=color:#f92672>.</span>load(<span style=color:#e6db74>&#34;s3a://sjm-airlines/people.csv&#34;</span>)
<span style=color:#f92672>&gt;&gt;&gt;</span> df<span style=color:#f92672>.</span>show()
<span style=color:#f92672>+-------+---+</span>
<span style=color:#f92672>|</span>   name<span style=color:#f92672>|</span>age<span style=color:#f92672>|</span>
<span style=color:#f92672>+-------+---+</span>
<span style=color:#f92672>|</span>Michael<span style=color:#f92672>|</span> <span style=color:#ae81ff>31</span><span style=color:#f92672>|</span>
<span style=color:#f92672>|</span>   Andy<span style=color:#f92672>|</span> <span style=color:#ae81ff>30</span><span style=color:#f92672>|</span>
<span style=color:#f92672>|</span> Justin<span style=color:#f92672>|</span> <span style=color:#ae81ff>19</span><span style=color:#f92672>|</span>
<span style=color:#f92672>+-------+---+</span>
<span style=color:#f92672>&gt;&gt;&gt;</span> df<span style=color:#f92672>.</span>select(<span style=color:#e6db74>&#34;*&#34;</span>)<span style=color:#f92672>.</span>filter(<span style=color:#e6db74>&#34;age &gt; 19&#34;</span>)<span style=color:#f92672>.</span>show()
<span style=color:#f92672>+-------+---+</span>
<span style=color:#f92672>|</span>   name<span style=color:#f92672>|</span>age<span style=color:#f92672>|</span>
<span style=color:#f92672>+-------+---+</span>
<span style=color:#f92672>|</span>Michael<span style=color:#f92672>|</span> <span style=color:#ae81ff>31</span><span style=color:#f92672>|</span>
<span style=color:#f92672>|</span>   Andy<span style=color:#f92672>|</span> <span style=color:#ae81ff>30</span><span style=color:#f92672>|</span>
<span style=color:#f92672>+-------+---+</span>
</code></pre></div><h3 id=connect-minio-and-spark-with-jupyternotebook>Connect Minio and Spark with Jupyter Notebook</h3>
<p>Follow the steps below to set up Jupyter:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=color:#75715e># Downloading shell script to install Jupyter using Anaconda</span>
wget https://repo.anaconda.com/archive/Anaconda3-2018.12-Linux-x86_64.sh
<span style=color:#75715e># Making the shell script executable</span>
chmod +x ./Anaconda3-2018.12-Linux-x86_64.sh
<span style=color:#75715e># Running the shell script with bash</span>
bash Anaconda3-2018.12-Linux-x86_64.sh
<span style=color:#75715e># Create new conda environment with minimal environment with only python installed.</span>
conda create -n myconda python<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>
<span style=color:#75715e># Put your self inside this environment run</span>
conda activate myconda
<span style=color:#75715e># Verify the Anaconda Python v3.x Terminal inside the environment. To exit, press CTRL+D or `exit()`</span>
python
<span style=color:#75715e># Install Jupyter Notebook inside the environment</span>
conda install jupyter
<span style=color:#75715e># Install findspark inside the environment using conda-forge channel</span>
conda install -c conda-forge findspark
<span style=color:#75715e># (Optional) Setting up jupyter notebook password, enter the desired password (If not set, have to use randomly generated tokens each time)</span>
jupyter notebook password
<span style=color:#75715e># Running Jupyter Notebook and making it available to public at port 8888</span>
jupyter notebook --ip 0.0.0.0  --port <span style=color:#ae81ff>8888</span>
</code></pre></div><p>You should be seeing the following, if everything goes well :</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=color:#f92672>[</span>I 06:50:01.156 NotebookApp<span style=color:#f92672>]</span> JupyterLab extension loaded from /home/prashant/anaconda3/lib/python3.7/site-packages/jupyterlab
<span style=color:#f92672>[</span>I 06:50:01.157 NotebookApp<span style=color:#f92672>]</span> JupyterLab application directory is /home/prashant/anaconda3/share/jupyter/lab
<span style=color:#f92672>[</span>I 06:50:01.158 NotebookApp<span style=color:#f92672>]</span> Serving notebooks from local directory: /home/prashant
<span style=color:#f92672>[</span>I 06:50:01.158 NotebookApp<span style=color:#f92672>]</span> The Jupyter Notebook is running at:
<span style=color:#f92672>[</span>I 06:50:01.158 NotebookApp<span style=color:#f92672>]</span> http://<span style=color:#f92672>(</span>instance-1 or 127.0.0.1<span style=color:#f92672>)</span>:8888/
<span style=color:#f92672>[</span>I 06:50:01.158 NotebookApp<span style=color:#f92672>]</span> Use Control-C to stop this server and shut down all kernels <span style=color:#f92672>(</span>twice to skip confirmation<span style=color:#f92672>)</span>.
</code></pre></div><h3 id=deactivate-conda-virtual-environment>Deactivate Conda virtual environment</h3>
<p>Example:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=color:#75715e># Usage: conda deactivate &lt;environment-name&gt;</span>
conda deactivate myconda
</code></pre></div><h3 id=converting-python-scriptspy-file-to-jupyter-notebookipynb-file>Converting python scripts(.py) file to Jupyter notebook(.ipynb) file</h3>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=color:#75715e># Installing p2j using python-pip</span>
pip install p2j
</code></pre></div><p>Example:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=color:#75715e># Generating .ipynb file out of some sample script.py using p2j</span>
p2j script.py
</code></pre></div><h3 id=converting-jupiter-notebookipynb-file-to-python-scriptspy-file>Converting Jupiter notebook(.ipynb) file to python scripts(.py) file</h3>
<p>You can make use of nbconvert that comes along with Jupiter. Example:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=color:#75715e># Generating script.py file out of some sample .ipynb file using jupyter nbconvert</span>
jupyter nbconvert script.ipynb
</code></pre></div><h3 id=creating-a-sample-pythonfile>Creating a sample python file</h3>
<p>Let&rsquo;s create a python file spark-minio.py with the codes below :</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#75715e># Import sys and print the python environment</span>
<span style=color:#f92672>import</span> sys
print(sys<span style=color:#f92672>.</span>executable)
<span style=color:#75715e># Import findspark to find spark make it accessible at run time</span>
<span style=color:#f92672>import</span> findspark
findspark<span style=color:#f92672>.</span>init()
<span style=color:#75715e># Import pyspark and its components</span>
<span style=color:#f92672>import</span> pyspark
<span style=color:#f92672>from</span> pyspark.sql.types <span style=color:#f92672>import</span> <span style=color:#f92672>*</span>
<span style=color:#f92672>from</span> pyspark.sql <span style=color:#f92672>import</span> SparkSession

<span style=color:#75715e># Creating SparkSession</span>
spark <span style=color:#f92672>=</span> SparkSession<span style=color:#f92672>.</span>builder<span style=color:#f92672>.</span>getOrCreate()
<span style=color:#75715e># Creating schema of the CSV fields</span>
schema <span style=color:#f92672>=</span> StructType([StructField(<span style=color:#e6db74>&#39;name&#39;</span>, StringType(), <span style=color:#66d9ef>True</span>),StructField(<span style=color:#e6db74>&#39;age&#39;</span>, IntegerType(), <span style=color:#66d9ef>True</span>)])
<span style=color:#75715e># Creating a dataframe from a csv in S3</span>
df <span style=color:#f92672>=</span> spark<span style=color:#f92672>.</span>read<span style=color:#f92672>.</span>format(<span style=color:#e6db74>&#34;csv&#34;</span>)<span style=color:#f92672>.</span>option(<span style=color:#e6db74>&#34;header&#34;</span>, <span style=color:#e6db74>&#34;true&#34;</span>)<span style=color:#f92672>.</span>load(<span style=color:#e6db74>&#34;s3a://sjm-airlines/people.csv&#34;</span>)
<span style=color:#75715e># Displaying all data in the CSV</span>
df<span style=color:#f92672>.</span>show()
<span style=color:#75715e># Displaying all the data in the csv for which age is greater than 19</span>
df<span style=color:#f92672>.</span>select(<span style=color:#e6db74>&#34;*&#34;</span>)<span style=color:#f92672>.</span>filter(<span style=color:#e6db74>&#34;age &gt; 19&#34;</span>)<span style=color:#f92672>.</span>show()
</code></pre></div><p>Now, converting the python code(spark-minio.py) to jupyter notebook compatible file (.ipynb) :</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=color:#75715e># Generating spark-minio.ipynb file out of spark-minio.py</span>
p2j spark-minio.py
</code></pre></div><h3 id=runningipynb-file-from-the-jupyter-notebookui>Running .ipynb file from the Jupyter notebook UI</h3>
<p>Let&rsquo;s open the UI running at http://(server-public-ip-address/localhost):8888/.
Enter the jupyter notebok password (or the token) and then, you should be seeing something like this :</p>
<p><img src=/images/data-analysis/2.jpg alt="Jupyter Notebook UI"></p>
<p>Select spark-minio.ipynb file and click on run, if everything went right, you should be getting the screen below :</p>
<p><img src=/images/data-analysis/3.jpg alt="Jupyter Notebook - loading people.csv"></p>
<p>Running Some Live Examples
 Before running the example, let&rsquo;s get compress the sample csv file with gzip compression.</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=color:#75715e># Generating gzip file named people.csv.gz file out of people.csv, while keeping the original file with -k flag</span>
gzip -k people.csv
<span style=color:#75715e># Copying the csv.gz file to the bucket using minio client</span>
mc cp people.csv.gz data/sjm-airlines
</code></pre></div><p> In Jupyter Notebook, go to File Tab > New Notebook > Python 3 (Or any other kernel). Try the following pyspark example on the data present in Minio. Note that the gzip compression is automatically detected with the .gz extension and handled when loading it with Spark&rsquo;s native csv format.</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>import</span> findspark
findspark<span style=color:#f92672>.</span>init()
<span style=color:#f92672>import</span> pyspark
<span style=color:#f92672>from</span> pyspark.sql.types <span style=color:#f92672>import</span> <span style=color:#f92672>*</span>
<span style=color:#f92672>from</span> pyspark.sql <span style=color:#f92672>import</span> SparkSession
spark <span style=color:#f92672>=</span> SparkSession<span style=color:#f92672>.</span>builder<span style=color:#f92672>.</span>getOrCreate()
schema <span style=color:#f92672>=</span> StructType([StructField(<span style=color:#e6db74>&#39;name&#39;</span>, StringType(), <span style=color:#66d9ef>True</span>),StructField(<span style=color:#e6db74>&#39;age&#39;</span>, IntegerType(), <span style=color:#66d9ef>True</span>)])
df <span style=color:#f92672>=</span> spark<span style=color:#f92672>.</span>read<span style=color:#f92672>.</span>format(<span style=color:#e6db74>&#34;csv&#34;</span>)<span style=color:#f92672>.</span>option(<span style=color:#e6db74>&#34;header&#34;</span>, <span style=color:#e6db74>&#34;true&#34;</span>)<span style=color:#f92672>.</span>load(<span style=color:#e6db74>&#34;s3a://sjm-airlines/people.csv.gz&#34;</span>)
df<span style=color:#f92672>.</span>createOrReplaceTempView(<span style=color:#e6db74>&#34;people&#34;</span>)
print(<span style=color:#e6db74>&#34;List of all people :&#34;</span>)
df2<span style=color:#f92672>.</span>show()
print(<span style=color:#e6db74>&#34;People with age less than 20 :&#34;</span>)
df2 <span style=color:#f92672>=</span> spark<span style=color:#f92672>.</span>sql(<span style=color:#e6db74>&#34;SELECT * FROM people where age&gt;20&#34;</span>)
df2<span style=color:#f92672>.</span>show()
</code></pre></div><p> If the steps are properly followed, you should be seeing the following in the jupyter notebook:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh>List of all people :
+-------+---+
|   name|age|
+-------+---+
|Michael| 31|
|   Andy| 30|
+-------+---+

People with age less than <span style=color:#ae81ff>20</span> :
+-------+---+
|   name|age|
+-------+---+
|Michael| 31|
|   Andy| 30|
+-------+---+
</code></pre></div><p> For the next example, we are gonna use SQL query capability of Spark dataframe on comparatively big CSV with 13 header fields and 2000251 entries. For the task, at first, we are gonna download the CSV with gzipped compression from the following link.</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh>wget https://gist.github.com/raw/d65254b1ac4b64c5969bd6309d8f8424/natality00.gz
</code></pre></div><p>Schema of the CSV and the description of each field can be found <a href=https://gist.github.com/raw/d65254b1ac4b64c5969bd6309d8f8424/natality-0-schema.md>HERE</a>.
 Create a new bucket in Minio, here, we are naming the bucket spark-experiment and upload the downloaded file to that bucket.
 You can use Minio UI for the task. Or, you can use Minio Client - mc for the same.</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=color:#75715e># Go to the `data` folder which Minio Server is pointing to </span>
cd ~/data
<span style=color:#75715e># Creating a new bucket</span>
mc mb spark-experiment
<span style=color:#75715e># Copying the compressed file inside the bucket</span>
mc cp ../natality00.gz spark-experiment
</code></pre></div><p> Now, let&rsquo;s try the following script in Jupyter notebook. You can either create a new cell in the same old notebook or create a new notebook for running the script. </p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>import</span> findspark
findspark<span style=color:#f92672>.</span>init()
<span style=color:#f92672>import</span> pyspark
<span style=color:#f92672>from</span> pyspark.sql.types <span style=color:#f92672>import</span> <span style=color:#f92672>*</span>
<span style=color:#f92672>from</span> pyspark.context <span style=color:#f92672>import</span> SparkContext
<span style=color:#f92672>from</span> pyspark.sql.session <span style=color:#f92672>import</span> SparkSession

sc <span style=color:#f92672>=</span> SparkContext<span style=color:#f92672>.</span>getOrCreate()
spark <span style=color:#f92672>=</span> SparkSession(sc)

df <span style=color:#f92672>=</span> spark<span style=color:#f92672>.</span>read<span style=color:#f92672>.</span>format(<span style=color:#e6db74>&#34;csv&#34;</span>)<span style=color:#f92672>.</span>option(<span style=color:#e6db74>&#34;header&#34;</span>, <span style=color:#e6db74>&#34;true&#34;</span>)<span style=color:#f92672>.</span>load(<span style=color:#e6db74>&#34;s3a://spark-experiment/natality00.gz&#34;</span>)
query<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;SELECT is_male, count(*) as count, AVG(weight_pounds) AS avg_weight FROM natality GROUP BY is_male&#34;</span>
df<span style=color:#f92672>.</span>createOrReplaceTempView(<span style=color:#e6db74>&#34;natality&#34;</span>)
df2 <span style=color:#f92672>=</span> spark<span style=color:#f92672>.</span>sql(query)
df2<span style=color:#f92672>.</span>show()
</code></pre></div><p>Upon running the script in the notebook, you should get the following output:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>+-------+-------+-----------------+</span>
<span style=color:#f92672>|</span>is_male<span style=color:#f92672>|</span>  count<span style=color:#f92672>|</span>       avg_weight<span style=color:#f92672>|</span>
<span style=color:#f92672>+-------+-------+-----------------+</span>
<span style=color:#f92672>|</span>  false<span style=color:#f92672>|</span> <span style=color:#ae81ff>975147</span><span style=color:#f92672>|</span> <span style=color:#ae81ff>7.17758067338709</span><span style=color:#f92672>|</span>
<span style=color:#f92672>|</span>   true<span style=color:#f92672>|</span><span style=color:#ae81ff>1025104</span><span style=color:#f92672>|</span><span style=color:#ae81ff>7.439839161360215</span><span style=color:#f92672>|</span>
<span style=color:#f92672>+-------+-------+-----------------+</span>
</code></pre></div><p>Visualization with charts and graphs using Pandas
Installation
 Install Pandas using conda. PySpark dataframe requires pandas >= 0.19.2 for executing any of the features by pandas.</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=color:#75715e># Installing pandas and matplotlib. Make sure inside the created conda virtual environment, when you are running the following command</span>
conda install pandas matplotlib
</code></pre></div><h2 id=reports-and-observations>Reports and Observations</h2>
<h3 id=report-1>Report 1</h3>
<p>Let&rsquo;s display some charts on the report that we got in the previous example. Let&rsquo;s create a new cell on the same notebook rather than integrating the following snippet in the above code, to reduce the time to plot multiple charts on the same report.</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>df3 <span style=color:#f92672>=</span> df2<span style=color:#f92672>.</span>toPandas()
df3<span style=color:#f92672>.</span>plot(x<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;is_male&#39;</span>, y<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;count&#39;</span>, kind<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;bar&#39;</span>)
df3<span style=color:#f92672>.</span>plot(x<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;is_male&#39;</span>, y<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;avg_weight&#39;</span>, kind<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;bar&#39;</span>)
</code></pre></div><p><img src=/images/data-analysis/4.jpg alt="Example 1 - gender vs count"> <img src=/images/data-analysis/5.jpg alt="Example 1 - gender vs average weight">
<em>Chart Graph of Is_Male Boolean VS Count and Average weight</em></p>
<p><strong>Observation</strong>: From the generated chart, we can observe that gender of the child doesn&rsquo;t
have any significant role neither in the average weight of the child nor wide difference
can be seen in a total count of the two gender divisions.</p>
<h3 id=report-2>Report 2</h3>
<p>Now, let us try another example. Let&rsquo;s create a new notebook for this. If you don&rsquo;t wish
to create a new one, you can try on a new cell of the previous notebook.</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>import</span> findspark
findspark<span style=color:#f92672>.</span>init()
<span style=color:#f92672>import</span> pyspark
<span style=color:#f92672>from</span> pyspark.sql.types <span style=color:#f92672>import</span> <span style=color:#f92672>*</span>

<span style=color:#f92672>from</span> pyspark.context <span style=color:#f92672>import</span> SparkContext
<span style=color:#f92672>from</span> pyspark.sql.session <span style=color:#f92672>import</span> SparkSession
sc <span style=color:#f92672>=</span> SparkContext<span style=color:#f92672>.</span>getOrCreate()
spark <span style=color:#f92672>=</span> SparkSession(sc)

df <span style=color:#f92672>=</span> spark<span style=color:#f92672>.</span>read<span style=color:#f92672>.</span>format(<span style=color:#e6db74>&#34;csv&#34;</span>)<span style=color:#f92672>.</span>option(<span style=color:#e6db74>&#34;header&#34;</span>, <span style=color:#e6db74>&#34;true&#34;</span>)<span style=color:#f92672>.</span>load(<span style=color:#e6db74>&#34;s3a://spark-experiment/natality00.gz&#34;</span>)
query<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;SELECT mother_age, count(*) as count, AVG(weight_pounds) AS avg_weight FROM natality GROUP BY mother_age&#34;</span>
df<span style=color:#f92672>.</span>createOrReplaceTempView(<span style=color:#e6db74>&#34;natality&#34;</span>)
print(<span style=color:#e6db74>&#34;Based on mother_age, total count and average weight is as follow : &#34;</span>)
df2 <span style=color:#f92672>=</span> spark<span style=color:#f92672>.</span>sql(query)
df3 <span style=color:#f92672>=</span> df2<span style=color:#f92672>.</span>toPandas()
df4<span style=color:#f92672>=</span> df3<span style=color:#f92672>.</span>sort_values(<span style=color:#e6db74>&#39;mother_age&#39;</span>)
print(<span style=color:#e6db74>&#34;***DONE***&#34;</span>)
</code></pre></div><p>After running the program, when it prints DONE. Create a new cell below and run the following snippet:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>df4<span style=color:#f92672>.</span>plot(x<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;mother_age&#39;</span>, y<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;count&#39;</span>)
df4<span style=color:#f92672>.</span>plot(x<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;mother_age&#39;</span>, y<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;avg_weight&#39;</span>)data
</code></pre></div><p><img src=/images/data-analysis/6.jpg alt="Example 2 - mother age vs count"> <img src=/images/data-analysis/7.jpg alt="Example 2 - mother age vs average weight">
<em>Chart Graph of Mother Age VS Count and Average weight</em></p>
<p><strong>Observation</strong> : We can observe that most of the mothers are between 20–30 age range when
they gave birth. While the average weight of the children shows some decline in case of mothers at a young
age, it shows a significant decrease in children&rsquo;s average weight in case of mothers at old age.</p>
<h3 id=report-3>Report 3</h3>
<p>This one will be an interesting one. We will plot a chart with a scatter graph.</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>import</span> findspark
findspark<span style=color:#f92672>.</span>init()
<span style=color:#f92672>import</span> pyspark
<span style=color:#f92672>from</span> pyspark.sql.types <span style=color:#f92672>import</span> <span style=color:#f92672>*</span>

<span style=color:#f92672>from</span> pyspark.context <span style=color:#f92672>import</span> SparkContext
<span style=color:#f92672>from</span> pyspark.sql.session <span style=color:#f92672>import</span> SparkSession
sc <span style=color:#f92672>=</span> SparkContext<span style=color:#f92672>.</span>getOrCreate()
spark <span style=color:#f92672>=</span> SparkSession(sc)

df <span style=color:#f92672>=</span> spark<span style=color:#f92672>.</span>read<span style=color:#f92672>.</span>format(<span style=color:#e6db74>&#34;csv&#34;</span>)<span style=color:#f92672>.</span>option(<span style=color:#e6db74>&#34;header&#34;</span>, <span style=color:#e6db74>&#34;true&#34;</span>)<span style=color:#f92672>.</span>load(<span style=color:#e6db74>&#34;s3a://spark-experiment/natality00.gz&#34;</span>)
query<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;SELECT INT(gestation_weeks), COUNT(*) AS count, AVG(weight_pounds) AS avg_weight FROM natality GROUP BY gestation_weeks&#34;</span>
df<span style=color:#f92672>.</span>createOrReplaceTempView(<span style=color:#e6db74>&#34;natality&#34;</span>)
print(<span style=color:#e6db74>&#34;Based on gestation_weeks, total count and average weight is as follow : &#34;</span>)
df2 <span style=color:#f92672>=</span> spark<span style=color:#f92672>.</span>sql(query)
df3 <span style=color:#f92672>=</span> df2<span style=color:#f92672>.</span>toPandas()
df4<span style=color:#f92672>=</span> df3<span style=color:#f92672>.</span>sort_values(<span style=color:#e6db74>&#39;gestation_weeks&#39;</span>)
print(<span style=color:#e6db74>&#34;***DONE***&#34;</span>)
</code></pre></div><p> Like we did before, after DONE is printed. Create a new cell below with the following snippet.
Here, we are introducing matplotlib&rsquo;s axes object(ax), and dataframe.describe().</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>import</span> matplotlib.pyplot <span style=color:#66d9ef>as</span> plt
fig, ax <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>subplots()
df4<span style=color:#f92672>.</span>plot(kind<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;scatter&#34;</span>, x<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;gestation_weeks&#34;</span>, y<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;avg_weight&#34;</span>, s<span style=color:#f92672>=</span><span style=color:#ae81ff>100</span>, c<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;count&#34;</span>, cmap<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;RdYlGn&#34;</span>, ax<span style=color:#f92672>=</span>ax)
df4<span style=color:#f92672>.</span>describe()
</code></pre></div><p><img src=/images/data-analysis/8.jpg alt="Example 3 - gestation week vs count"> <img src=/images/data-analysis/9.jpg alt="Example 3 - gestation week vs average weight">
<em>Scatter Graph and Data Frame Description of Gestation week VS Count and Average weight</em></p>
<p><strong>Observation</strong>: From the scatter graph, it can be seen that the maximum number of mothers'
gestation period was 40 weeks and children born around this period are mostly of more
weight than rest. It can be seen that there are around 100k entries for which <code>gestation_weeks</code>
is 99, which is not possible in reality. So, it can be concluded that 99 is the dummy
value present for those whose gestation period data wasn&rsquo;t available.</p>
<p><em>Note: List of possible cmap i.e. colormap can be found <a href=https://gist.github.com/ab86e34febe7dba1d05bf0b2b7f56611>here</a>.</em></p>
<hr>
<ul class="pa0 mb0">
<li class=list style=display:inline>
<a href=/tags/apache-spark class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">apache spark</a>
</li>
<li class=list style=display:inline>
<a href=/tags/big-data class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">big data</a>
</li>
<li class=list style=display:inline>
<a href=/tags/data-analysis class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">data analysis</a>
</li>
<li class=list style=display:inline>
<a href=/tags/jupyter-notebook class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">jupyter notebook</a>
</li>
<li class=list style=display:inline>
<a href=/tags/minio class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">minio</a>
</li>
<li class=list style=display:inline>
<a href=/tags/pandas class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">pandas</a>
</li>
</ul>
<div class="mt6 instapaper_ignoref">
<div id=disqus_thread></div>
<script type=application/javascript>var disqus_config=function(){};(function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById('disqus_thread').innerHTML='Disqus comments not available by default when the website is previewed locally.';return}var b=document,a=b.createElement('script');a.async=!0,a.src='//prashantshahi.disqus.com/embed.js',a.setAttribute('data-timestamp',+new Date),(b.head||b.body).appendChild(a)})()</script>
<noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript>
<a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a>
</div>
</div>
<aside class="w-30-l mt6-l"><div class="bg-light-gray pa3 nested-list-reset nested-copy-line-height nested-links">
<p class="f5 b mb3">What's in this blog</p>
<nav id=TableOfContents>
<ul>
<li><a href=#brief-overview-of-the-components>Brief Overview of the components</a></li>
<li><a href=#setup>Setup</a>
<ul>
<li><a href=#system-configuration-vminstance>System configuration (VM/Instance)</a></li>
<li><a href=#downloading-minio-server-andclient>Downloading Minio Server and Client</a></li>
<li><a href=#minio-client>Minio Client</a></li>
<li><a href=#loading-sampledata>Loading Sample Data</a></li>
<li><a href=#setting-up-java-environment-for-sparkshell>Setting up Java Environment for Spark Shell</a></li>
<li><a href=#installation-of-apache-spark-andhadoop>Installation of Apache Spark and Hadoop</a></li>
<li><a href=#setting-up-minio-server-endpoint-and-credentials>Setting up Minio Server endpoint and credentials</a></li>
</ul>
</li>
<li><a href=#get-started>Get started</a>
<ul>
<li><a href=#spark-shell-on-csv-in-minios3>Spark Shell on CSV in Minio (S3)</a></li>
<li><a href=#spark-shell-using-pyspark-andminio>Spark-Shell using PySpark and Minio</a></li>
<li><a href=#connect-minio-and-spark-with-jupyternotebook>Connect Minio and Spark with Jupyter Notebook</a></li>
<li><a href=#deactivate-conda-virtual-environment>Deactivate Conda virtual environment</a></li>
<li><a href=#converting-python-scriptspy-file-to-jupyter-notebookipynb-file>Converting python scripts(.py) file to Jupyter notebook(.ipynb) file</a></li>
<li><a href=#converting-jupiter-notebookipynb-file-to-python-scriptspy-file>Converting Jupiter notebook(.ipynb) file to python scripts(.py) file</a></li>
<li><a href=#creating-a-sample-pythonfile>Creating a sample python file</a></li>
<li><a href=#runningipynb-file-from-the-jupyter-notebookui>Running .ipynb file from the Jupyter notebook UI</a></li>
</ul>
</li>
<li><a href=#reports-and-observations>Reports and Observations</a>
<ul>
<li><a href=#report-1>Report 1</a></li>
<li><a href=#report-2>Report 2</a></li>
<li><a href=#report-3>Report 3</a></li>
</ul>
</li>
</ul>
</nav>
</div>
</aside>
</article>
</main>
<footer class="bg-black bottom-0 w-100 pa3" role=contentinfo>
<div class="flex justify-between">
<a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href=https://prashantshahi.dev/>
&copy; prashantshahi.dev 2022
</a>
<div>
<a href=https://twitter.com/c0degeas target=_blank class="link-transition twitter link dib z-999 pt3 pt0-l mr1" title="Twitter link" rel=noopener aria-label="follow on Twitter——Opens in a new window"><svg height="32" style="enable-background:new 0 0 67 67" viewBox="0 0 67 67" width="32" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M37.167 22.283c-2.619.953-4.274 3.411-4.086 6.101l.063 1.038-1.048-.127c-3.813-.487-7.145-2.139-9.974-4.915l-1.383-1.377-.356 1.017c-.754 2.267-.272 4.661 1.299 6.271.838.89.649 1.017-.796.487-.503-.169-.943-.296-.985-.233-.146.149.356 2.076.754 2.839.545 1.06 1.655 2.097 2.871 2.712l1.027.487-1.215.021c-1.173.0-1.215.021-1.089.467.419 1.377 2.074 2.839 3.918 3.475l1.299.444-1.131.678c-1.676.976-3.646 1.526-5.616 1.568C19.775 43.256 19 43.341 19 43.405c0 .211 2.557 1.397 4.044 1.864 4.463 1.377 9.765.783 13.746-1.568 2.829-1.673 5.657-5 6.978-8.221.713-1.716 1.425-4.851 1.425-6.354.0-.975.063-1.102 1.236-2.267.692-.678 1.341-1.419 1.467-1.631.21-.403.188-.403-.88-.043-1.781.636-2.033.551-1.152-.402.649-.678 1.425-1.907 1.425-2.267.0-.063-.314.042-.671.233-.377.212-1.215.53-1.844.72l-1.131.361-1.027-.7c-.566-.381-1.361-.805-1.781-.932C39.766 21.902 38.131 21.944 37.167 22.283zM33 64C16.432 64 3 50.569 3 34S16.432 4 33 4s30 13.431 30 30S49.568 64 33 64z" style="fill-rule:evenodd;clip-rule:evenodd;fill:"/></svg>
<span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" width="8" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:"/></svg>
</span></a>
<a href=https://www.linkedin.com/in/prashantshahi target=_blank class="link-transition linkedin link dib z-999 pt3 pt0-l mr1" title="LinkedIn link" rel=noopener aria-label="follow on LinkedIn——Opens in a new window"><svg height="32" style="enable-background:new 0 0 65 65" viewBox="0 0 65 65" width="32" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M50.837 48.137V36.425c0-6.275-3.35-9.195-7.816-9.195-3.604.0-5.219 1.983-6.119 3.374V27.71h-6.79c.09 1.917.0 20.427.0 20.427h6.79V36.729c0-.609.044-1.219.224-1.655.49-1.22 1.607-2.483 3.482-2.483 2.458.0 3.44 1.873 3.44 4.618v10.929H50.837zM22.959 24.922c2.367.0 3.842-1.57 3.842-3.531-.044-2.003-1.475-3.528-3.797-3.528s-3.841 1.524-3.841 3.528c0 1.961 1.474 3.531 3.753 3.531H22.959zM34 64C17.432 64 4 50.568 4 34 4 17.431 17.432 4 34 4s30 13.431 30 30c0 16.568-13.432 30-30 30zM26.354 48.137V27.71h-6.789v20.427h6.789z" style="fill-rule:evenodd;clip-rule:evenodd;fill:"/></svg>
<span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" width="8" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:"/></svg>
</span></a>
<a href=https://gitlab.com/prashant-shahi target=_blank class="link-transition github link dib z-999 pt3 pt0-l mr1" title="Github link" rel=noopener aria-label="follow on Github——Opens in a new window"><svg height="32" style="enable-background:new 0 0 512 512" viewBox="0 0 512 512" width="32" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M256 32C132.3 32 32 134.8 32 261.7c0 101.5 64.2 187.5 153.2 217.9 11.2 2.1 15.3-5 15.3-11.1.0-5.5-.2-19.9-.3-39.1-62.3 13.9-75.5-30.8-75.5-30.8-10.2-26.5-24.9-33.6-24.9-33.6-20.3-14.3 1.5-14 1.5-14 22.5 1.6 34.3 23.7 34.3 23.7 20 35.1 52.4 25 65.2 19.1 2-14.8 7.8-25 14.2-30.7-49.7-5.8-102-25.5-102-113.5.0-25.1 8.7-45.6 23-61.6-2.3-5.8-10-29.2 2.2-60.8.0.0 18.8-6.2 61.6 23.5 17.9-5.1 37-7.6 56.1-7.7 19 .1 38.2 2.6 56.1 7.7 42.8-29.7 61.5-23.5 61.5-23.5 12.2 31.6 4.5 55 2.2 60.8 14.3 16.1 23 36.6 23 61.6.0 88.2-52.4 107.6-102.3 113.3 8 7.1 15.2 21.1 15.2 42.5.0 30.7-.3 55.5-.3 63 0 6.1 4 13.3 15.4 11C415.9 449.1 480 363.1 480 261.7 480 134.8 379.7 32 256 32z"/></svg>
<span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" width="8" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:"/></svg>
</span></a>
<a href=https://keybase.io/prashant_s target=_blank class="link-transition keybase link dib z-999 pt3 pt0-l mr1" title="Keybase link" rel=noopener aria-label="follow on Keybase——Opens in a new window"><svg height="32" style="enable-background:new 0 0 33 33" viewBox="0 0 33 33" width="32" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M16.1477825.840201442C7.31178255.840201442.147782547 8.00420144.147782547 16.8402014c0 8.836 7.164000003 16 15.999999953 16 8.836.0 16-7.164 16-16 0-8.83599996-7.164-15.999999958-16-15.999999958zM14.533 26.371C14.533 26.899 14.105 27.324 13.579 27.324 13.054 27.324 12.625 26.899 12.625 26.371 12.625 25.845 13.053 25.417 13.578 25.417 14.102 25.417 14.529 25.848 14.529 26.372M14.75 5l1.207.71c-.596 1.271-.529 1.743-.496 1.848C15.942 7.544 16.516 7.647 17.172 7.863c1.082.36 1.947 1.125 2.438 2.16C20.097 11.055 20.14 12.214 19.73 13.278 19.719 13.306 19.707 13.334 19.695 13.361L19.925 13.439C21.375 13.957 22.72 14.804 23.88 15.943 23.898 15.962 23.915 15.978 23.93 15.996L24.065 16.127 24.156 16.226 24.232 16.306C24.342 16.426 24.447 16.545 24.551 16.665 24.598 16.721 24.647 16.773 24.692 16.834 24.739 16.893 24.789 16.949 24.835 17.009L24.991 17.213c1.398 1.853 2.183 4.075 2.184 6.274C27.175 25.567 26.77 27.436 25.994 28.999H24.383c1.125-1.825 1.38-3.949 1.38-5.512C25.763 22.989 25.713 22.489 25.622 21.991L25.518 22.156c-.913 1.296-2.668 1.789-4.473 1.257C16.879 22.192 13.21 22.708 10.135 24.942L8.395 26.21 9.38 23.119l-1.913 2.03c.261 1.422.847 2.734 1.68 3.848H7.45c-.493-.808-.879-1.685-1.145-2.615L5 27.769 5.0005667 25.4970384C5.01020062 22.6453117 5.18361111 19.2052778 8.305 16.048c1.074-1.083 2.314-1.922 3.66-2.484C11.633 12.878 11.495 12.098 11.56 11.258L10.558 11.197C9.53 11.133 8.742 10.247 8.803 9.218V9.215L8.891 7.813C8.951 6.829 9.771 6.058 10.761 6.058 10.795 6.058 10.832 6.058 10.865 6.061H10.877L12.273 6.147C12.752 6.175 13.19 6.382 13.518 6.727 13.815 6.294 14.133 5.854 14.463 5.399L14.75 5zm4.743 20.417C20.019 25.417 20.447 25.848 20.447 26.372L20.451 26.371C20.451 26.899 20.023 27.324 19.496 27.324 18.97 27.324 18.544 26.899 18.544 26.371 18.544 25.845 18.967 25.417 19.493 25.417zM12.981 11.191C13.104 10.189 13.559 9.242 14.211 8.221 14.236 8.271 14.265 8.318 14.295 8.365 14.559 8.763 15.008 8.99 15.494 8.97 15.711 8.962 16.099 8.995 16.727 9.202 17.441 9.438 18.013 9.946 18.335 10.627 18.657 11.308 18.684 12.069 18.414 12.776 18.241 13.221 17.96 13.596 17.608 13.885L17.2 13.383 17.198 13.38C16.919 13.039 16.504 12.845 16.064 12.845 15.729 12.845 15.4 12.962 15.139 13.175 14.805 13.445 14.625 13.835 14.605 14.233c-1.2-.541-1.8-1.643-1.628-3.041L12.981 11.191zm4.304 5.11L16.766 16.726C16.72 16.762 16.671 16.779 16.62 16.779 16.554 16.779 16.487 16.749 16.443 16.694L16.332 16.559C16.249 16.459 16.265 16.309 16.366 16.225L16.876 15.805l-1.055-1.299C15.712 14.373 15.73 14.176 15.865 14.07 15.923 14.022 15.991 13.998 16.059 13.998 16.15 13.998 16.24 14.036 16.299 14.111l2.963 3.645C19.371 17.891 19.352 18.086 19.22 18.192 19.181 18.221 19.138 18.245 19.094 18.255 19.071 18.261 19.049 18.264 19.024 18.264 18.934 18.264 18.846 18.224 18.784 18.151L18.489 17.786 17.444 18.64C17.398 18.677 17.344 18.695 17.29 18.695 17.222 18.695 17.151 18.665 17.104 18.605L16.627 18.026C16.545 17.924 16.559 17.774 16.662 17.69L17.713 16.833 17.287 16.3 17.285 16.301zM11.84 9.866 10.644 9.791C10.389 9.776 10.194 9.556 10.209 9.303L10.299 7.902C10.313 7.657 10.515 7.466 10.76 7.466H10.784L12.185 7.557C12.308 7.563 12.421 7.617 12.502 7.709 12.585 7.803 12.625 7.919 12.618 8.045L12.611 8.146C12.291 8.713 12.026 9.28 11.838 9.866H11.84zM24.364 21.347C23.799 22.152 22.677 22.428 21.44 22.065 17.554 20.924 14.044 21.162 10.972 22.766l1.636-5.123-5.291 5.609C7.416 19.49 9.77 16.286 13.075 14.941 13.546 15.314 14.109 15.601 14.748 15.782 14.908 15.826 15.07 15.856 15.228 15.884 15.045 16.342 15.109 16.881 15.438 17.291L15.513 17.381C15.341 17.831 15.408 18.356 15.734 18.755L16.209 19.337C16.475 19.662 16.868 19.85 17.288 19.85 17.609 19.85 17.923 19.739 18.174 19.536L18.459 19.304C18.633 19.378 18.826 19.417 19.025 19.417 19.138 19.417 19.247 19.407 19.355 19.382 19.573 19.332 19.779 19.232 19.953 19.091 20.576 18.581 20.673 17.656 20.162 17.031l-1.67-2.056C18.637 14.858 18.773 14.731 18.9 14.594 19.035 14.631 19.171 14.672 19.3 14.714 19.566 14.811 19.833 14.912 20.095 15.029c1.005.445 1.954 1.1 2.771 1.897C22.895 16.956 22.925 16.981 22.951 17.009L23.121 17.184C23.159 17.223 23.197 17.263 23.232 17.304 23.311 17.389 23.392 17.479 23.471 17.571L23.597 17.721C23.642 17.774 23.683 17.825 23.727 17.881L23.841 18.031C23.881 18.082 23.92 18.133 23.958 18.185 24.796 19.334 24.945 20.514 24.362 21.342V21.347H24.364zM11.806 9.115 10.971 9.064 11.024 8.229 11.858 8.28 11.806 9.115z" style="fill-rule:evenodd;clip-rule:evenodd;fill:"/></svg>
<span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" width="8" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:"/></svg>
</span></a>
</div>
</div>
</footer>
<script src=/dist/js/app.3fc0f988d21662902933.js></script>
</body>
</html>