<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>Prashant&#39;s Scrapbook  | Data Analysis using Sparks, Pandas, and Matplotlib using Jupyter Notebook for data in S3(Minio)</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="generator" content="Hugo 0.91.2" />
    
    
      <META NAME="ROBOTS" CONTENT="INDEX, FOLLOW">
    

    
    
      <link href="/dist/css/app.1cb140d8ba31d5b2f1114537dd04802a.css" rel="stylesheet">
    

    

    
      
    

    
    
    <meta property="og:title" content="Data Analysis using Sparks, Pandas, and Matplotlib using Jupyter Notebook for data in S3(Minio)" />
<meta property="og:description" content="Data Analysis is to understand problems facing an organization and to explore data in meaningful ways. Data in itself is merely facts and figures. Evaluation of the data can provide advantages to the organization and aid in making business decisions.
Brief Overview of the components Apache Spark is a lightning-fast cluster computing technology, designed for fast computation and based on Hadoop MapReduce.
Pandas is a software library written in Python for data manipulation and analysis." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://prashantshahi.dev/blog/data-analysis-spark-minio/" /><meta property="article:section" content="blog" />
<meta property="article:published_time" content="2019-05-13T08:30:00+05:30" />
<meta property="article:modified_time" content="2019-05-13T08:30:00+05:30" />

<meta itemprop="name" content="Data Analysis using Sparks, Pandas, and Matplotlib using Jupyter Notebook for data in S3(Minio)">
<meta itemprop="description" content="Data Analysis is to understand problems facing an organization and to explore data in meaningful ways. Data in itself is merely facts and figures. Evaluation of the data can provide advantages to the organization and aid in making business decisions.
Brief Overview of the components Apache Spark is a lightning-fast cluster computing technology, designed for fast computation and based on Hadoop MapReduce.
Pandas is a software library written in Python for data manipulation and analysis."><meta itemprop="datePublished" content="2019-05-13T08:30:00+05:30" />
<meta itemprop="dateModified" content="2019-05-13T08:30:00+05:30" />
<meta itemprop="wordCount" content="2709">
<meta itemprop="keywords" content="apache spark,big data,data analysis,jupyter notebook,minio,pandas," /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Data Analysis using Sparks, Pandas, and Matplotlib using Jupyter Notebook for data in S3(Minio)"/>
<meta name="twitter:description" content="Data Analysis is to understand problems facing an organization and to explore data in meaningful ways. Data in itself is merely facts and figures. Evaluation of the data can provide advantages to the organization and aid in making business decisions.
Brief Overview of the components Apache Spark is a lightning-fast cluster computing technology, designed for fast computation and based on Hadoop MapReduce.
Pandas is a software library written in Python for data manipulation and analysis."/>

      
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-116535819-4', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

    
  </head>

  <body class="ma0 avenir bg-near-white">

    
   
  

  <header>
    <div class="bg-black">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="https://prashantshahi.dev" class="f3 fw2 hover-white no-underline white-90 dib">
      Prashant&#39;s Scrapbook
    </a>
    <div class="flex-l items-center">
      

      
        <ul class="pl0 mr3">
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="" title="Home page">
              Home
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="" title="Blog page">
              Blog
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="" title="About page">
              About
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="" title="Work page">
              Work
            </a>
          </li>
          
        </ul>
      
      
    </div>
  </div>
</nav>

    </div>
  </header>



    <main class="pb5" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref b helvetica tracked">
          
        BLOG
      </aside>
      




  <div id="sharing" class="mt3">

    
    <a href="https://www.facebook.com/sharer.php?u=%25!s%28%3cnil%3e%29" class="facebook no-underline" aria-label="share on Facebook">
      <svg height="32px"  style="enable-background:new 0 0 67 67;" version="1.1" viewBox="0 0 67 67" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M28.765,50.32h6.744V33.998h4.499l0.596-5.624h-5.095  l0.007-2.816c0-1.466,0.14-2.253,2.244-2.253h2.812V17.68h-4.5c-5.405,0-7.307,2.729-7.307,7.317v3.377h-3.369v5.625h3.369V50.32z   M33,64C16.432,64,3,50.569,3,34S16.432,4,33,4s30,13.431,30,30S49.568,64,33,64z" style="fill-rule:evenodd;clip-rule:evenodd;"/></svg>

    </a>

    
    
    <a href="https://twitter.com/share?url=%25!s%28%3cnil%3e%29&amp;text=Data%20Analysis%20using%20Sparks,%20Pandas,%20and%20Matplotlib%20using%20Jupyter%20Notebook%20for%20data%20in%20S3%28Minio%29" class="twitter no-underline" aria-label="share on Twitter">
      <svg height="32px"  style="enable-background:new 0 0 67 67;" version="1.1" viewBox="0 0 67 67" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M37.167,22.283c-2.619,0.953-4.274,3.411-4.086,6.101  l0.063,1.038l-1.048-0.127c-3.813-0.487-7.145-2.139-9.974-4.915l-1.383-1.377l-0.356,1.017c-0.754,2.267-0.272,4.661,1.299,6.271  c0.838,0.89,0.649,1.017-0.796,0.487c-0.503-0.169-0.943-0.296-0.985-0.233c-0.146,0.149,0.356,2.076,0.754,2.839  c0.545,1.06,1.655,2.097,2.871,2.712l1.027,0.487l-1.215,0.021c-1.173,0-1.215,0.021-1.089,0.467  c0.419,1.377,2.074,2.839,3.918,3.475l1.299,0.444l-1.131,0.678c-1.676,0.976-3.646,1.526-5.616,1.568  C19.775,43.256,19,43.341,19,43.405c0,0.211,2.557,1.397,4.044,1.864c4.463,1.377,9.765,0.783,13.746-1.568  c2.829-1.673,5.657-5,6.978-8.221c0.713-1.716,1.425-4.851,1.425-6.354c0-0.975,0.063-1.102,1.236-2.267  c0.692-0.678,1.341-1.419,1.467-1.631c0.21-0.403,0.188-0.403-0.88-0.043c-1.781,0.636-2.033,0.551-1.152-0.402  c0.649-0.678,1.425-1.907,1.425-2.267c0-0.063-0.314,0.042-0.671,0.233c-0.377,0.212-1.215,0.53-1.844,0.72l-1.131,0.361l-1.027-0.7  c-0.566-0.381-1.361-0.805-1.781-0.932C39.766,21.902,38.131,21.944,37.167,22.283z M33,64C16.432,64,3,50.569,3,34S16.432,4,33,4  s30,13.431,30,30S49.568,64,33,64z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/></svg>

    </a>

    
    <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=%25!s%28%3cnil%3e%29&amp;title=Data%20Analysis%20using%20Sparks,%20Pandas,%20and%20Matplotlib%20using%20Jupyter%20Notebook%20for%20data%20in%20S3%28Minio%29" class="linkedin no-underline" aria-label="share on LinkedIn">
      <svg  height="32px"  style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>

    </a>
  </div>

      <h1 class="f1 athelas mt3 mb1">Data Analysis using Sparks, Pandas, and Matplotlib using Jupyter Notebook for data in S3(Minio)</h1>
      
      <p class="tracked">
          By <strong>
          
              Prashant Shahi
          
          </strong>
      </p>
      
      
      <time class="f6 mv4 dib tracked" datetime="2019-05-13T08:30:00&#43;05:30">May 13, 2019</time>

      
      
        <span class="f6 mv4 dib tracked"> - 13 minutes read</span>
        <span class="f6 mv4 dib tracked"> - 2709 words</span>
      
    </header>
    <div class="nested-copy-line-height lh-copy serif f4 nested-links nested-img mid-gray pr4-l w-two-thirds-l"><p><strong>Data Analysis</strong> is to understand problems facing an organization and to explore data in
meaningful ways. Data in itself is merely facts and figures. Evaluation of the data can
provide advantages to the organization and aid in making business decisions.</p>
<h2 id="brief-overview-of-the-components">Brief Overview of the components</h2>
<p><strong>Apache Spark</strong> is a lightning-fast cluster computing technology, designed for fast
computation and based on Hadoop MapReduce.</p>
<p><strong>Pandas</strong> is a software library written in Python for data manipulation and analysis.
Similarly, <strong>Matplotlib</strong> is another python library used for 2D plotting which produces
publication quality figures in a variety of hardcopy formats and interactive
environments across platforms.</p>
<p><strong>Jupyter Notebook</strong> is an open-source web application that allows you to create and
share documents that contain live code, equations, visualizations, and narrative text. </p>
<p><strong>Minio</strong> is an open-source cloud object storage server which follows Amazon S3 protocol
and at times, referred to as an Open-Source Amazon S3 alternative, which is available for
anyone on internet for free to deploy on their machines.</p>
<h2 id="setup">Setup</h2>
<h3 id="system-configuration-vminstance">System configuration (VM/Instance)</h3>
<p>The system configuration selected for the task is as mentioned below :</p>
<ul>
<li>6 cores CPUs</li>
<li>10 GB memory (RAM)</li>
<li>200 GB Disk Size (ROM)</li>
</ul>
<p>It should be fine even if your machine configurations are lower the one used here.</p>
<h3 id="downloading-minio-server-andclient">Downloading Minio Server and Client</h3>
<p><strong>Minio Server</strong></p>
<p>Follow the steps below to setup Minio Server : </p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-sh" data-lang="sh"><span style="color:#75715e"># Downloading Minio binary and copying to /opt</span>
sudo wget -O /opt/minio https://dl.minio.io/server/minio/release/linux-amd64/minio
<span style="color:#75715e"># Changing the file permission of binary to mark as executable</span>
sudo chmod +x /opt/minio
<span style="color:#75715e"># Creating a symbolic link to /usr/local/bin to make the file executable from any path</span>
sudo ln -s /opt/minio /usr/local/bin/
<span style="color:#75715e"># Making the data directory for storing the objects/data for minio server</span>
mkdir ./data
<span style="color:#75715e"># Running the Minio server with the data directory parameter</span>
minio server ./data
</code></pre></div><h3 id="minio-client">Minio Client</h3>
<p>Follow the steps below to setup Minio Client :</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-sh" data-lang="sh"><span style="color:#75715e"># Downloading minio binary and copying to /opt</span>
sudo wget -O /opt/mc https://dl.minio.io/client/mc/release/linux-amd64/mc
<span style="color:#75715e"># Changing the file permission of binary to mark as executable</span>
sudo chmod +x /opt/mc
<span style="color:#75715e"># Creatin a symbolic link to /usr/local/bin to make the file executable from any path</span>
sudo ln -s /opt/mc /usr/local/bin
<span style="color:#75715e"># Executing the command with help parameter to ensure that installation was a success</span>
mc --help
</code></pre></div><h3 id="loading-sampledata">Loading Sample Data</h3>
<p>Follow the steps below how to load a Sample Data to S3 using Minio Client :</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-sh" data-lang="sh"><span style="color:#75715e"># Downloading the sample data of TotalPopulationBySex.csv from UN</span>
wget -O TotalPopulation.csv <span style="color:#e6db74">&#34;https://esa.un.org/unpd/wpp/DVD/Files/1_Indicators%20(Standard)/CSV_FILES/WPP2017_TotalPopulationBySex.csv&#34;</span>
<span style="color:#75715e"># Compressing the csv file</span>
gzip TotalPopulation.csv
<span style="color:#75715e"># Creating a new bucket</span>
mc mb data/mycsvbucket
<span style="color:#75715e"># Copying the compressed file inside bucket</span>
mc cp TotalPopulation.csv.gz data/mycsvbucket/
</code></pre></div><h3 id="setting-up-java-environment-for-sparkshell">Setting up Java Environment for Spark Shell</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-sh" data-lang="sh"><span style="color:#75715e"># Adding ppa to local repository</span>
sudo add-apt-repository ppa:webupd8team/java
<span style="color:#75715e"># Updating repository archives</span>
sudo apt update
<span style="color:#75715e"># Installing Oracle Java8</span>
sudo apt install -y oracle-java8-installer
<span style="color:#75715e"># Verifying the java installation</span>
javac -version
<span style="color:#75715e"># Setting Oracle Java8 as default (In case of multiple java versions)</span>
sudo apt install -y oracle-java8-set-default
<span style="color:#75715e"># Setting up environment variable (Also, add this to the `~/.bashrc` file to apply for next boot)</span>
export JAVA_HOME<span style="color:#f92672">=</span>/usr/lib/jvm/java-8-oracle
export PATH<span style="color:#f92672">=</span>$PATH:$JAVA_HOME/bin
</code></pre></div><h3 id="installation-of-apache-spark-andhadoop">Installation of Apache Spark and Hadoop</h3>
<p>Steps to install Apache Spark is as follow :</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-sh" data-lang="sh"><span style="color:#75715e"># Download Spark v2.3.0 without Hadoop</span>
wget http://archive.apache.org/dist/spark/spark-2.3.0/spark-2.3.0-bin-without-hadoop.tgz
<span style="color:#75715e"># Extracting the compressed file</span>
sudo tar -C /opt/ -xvf spark-2.3.0-bin-without-hadoop.tgz
<span style="color:#75715e"># Setting up environment variable (Also, add this to the `~/.bashrc` file to apply for next boot)</span>
export SPARK_HOME<span style="color:#f92672">=</span>/opt/spark-2.3.0-bin-without-hadoop
export PATH<span style="color:#f92672">=</span>$PATH:$SPARK_HOME/bin
</code></pre></div><p>Steps to install Apache Hadoop is as follow :</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-sh" data-lang="sh"><span style="color:#75715e"># Download Hadoop v2.8.2</span>
wget https://archive.apache.org/dist/hadoop/core/hadoop-2.8.2/hadoop-2.8.2.tar.gz
<span style="color:#75715e"># Extracting the compressed file</span>
sudo tar -C /opt/ -xvf hadoop-2.8.2.tar.gz
<span style="color:#75715e"># Setting up environment for Hadoop</span>
export HADOOP_HOME<span style="color:#f92672">=</span>/opt/hadoop-2.8.2
export PATH<span style="color:#f92672">=</span>$PATH:$HADOOP_HOME/bin
export SPARK_DIST_CLASSPATH<span style="color:#f92672">=</span><span style="color:#66d9ef">$(</span>hadoop classpath<span style="color:#66d9ef">)</span>
export LD_LIBRARY_PATH<span style="color:#f92672">=</span>$HADOOP_HOME/lib/native
</code></pre></div><h3 id="setting-up-minio-server-endpoint-and-credentials">Setting up Minio Server endpoint and credentials</h3>
<p>Open the file $HADOOP_HOME/etc/hadoop/core-site.xml for editing.
In the example XML file below, Minio server is running at http://127.0.0.1:9000
with access key minio and secret key minio123. Make sure to update relevant sections
with valid Minio server endpoint and credentials.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-xml" data-lang="xml"><span style="color:#75715e">&lt;?xml version=&#34;1.0&#34; encoding=&#34;UTF-8&#34;?&gt;</span>
<span style="color:#75715e">&lt;?xml-stylesheet type=&#34;text/xsl&#34; href=&#34;configuration.xsl&#34;?&gt;</span>

<span style="color:#f92672">&lt;configuration&gt;</span>
  <span style="color:#f92672">&lt;property&gt;</span>
    <span style="color:#f92672">&lt;name&gt;</span>fs.s3a.endpoint<span style="color:#f92672">&lt;/name&gt;</span>
    <span style="color:#f92672">&lt;description&gt;</span>AWS S3 endpoint to connect to. An up-to-date list is
      provided in the AWS Documentation: regions and endpoints. Without this
      property, the standard region (s3.amazonaws.com) is assumed.
    <span style="color:#f92672">&lt;/description&gt;</span>
    <span style="color:#f92672">&lt;value&gt;</span>http://127.0.0.1:9000<span style="color:#f92672">&lt;/value&gt;</span>
  <span style="color:#f92672">&lt;/property&gt;</span>

  <span style="color:#f92672">&lt;property&gt;</span>
    <span style="color:#f92672">&lt;name&gt;</span>fs.s3a.access.key<span style="color:#f92672">&lt;/name&gt;</span>
    <span style="color:#f92672">&lt;description&gt;</span>AWS access key ID.<span style="color:#f92672">&lt;/description&gt;</span>
    <span style="color:#f92672">&lt;value&gt;</span>minio<span style="color:#f92672">&lt;/value&gt;</span>
  <span style="color:#f92672">&lt;/property&gt;</span>

  <span style="color:#f92672">&lt;property&gt;</span>
    <span style="color:#f92672">&lt;name&gt;</span>fs.s3a.secret.key<span style="color:#f92672">&lt;/name&gt;</span>
    <span style="color:#f92672">&lt;description&gt;</span>AWS secret key.<span style="color:#f92672">&lt;/description&gt;</span>
    <span style="color:#f92672">&lt;value&gt;</span>minio123<span style="color:#f92672">&lt;/value&gt;</span>
  <span style="color:#f92672">&lt;/property&gt;</span>

  <span style="color:#f92672">&lt;property&gt;</span>
    <span style="color:#f92672">&lt;name&gt;</span>fs.s3a.path.style.access<span style="color:#f92672">&lt;/name&gt;</span>
    <span style="color:#f92672">&lt;value&gt;</span>true<span style="color:#f92672">&lt;/value&gt;</span>
    <span style="color:#f92672">&lt;description&gt;</span>Enable S3 path style access ie disabling the default virtual hosting behaviour.
      Useful for S3A-compliant storage providers as it removes the need to set up DNS for virtual hosting.
    <span style="color:#f92672">&lt;/description&gt;</span>
  <span style="color:#f92672">&lt;/property&gt;</span>

  <span style="color:#f92672">&lt;property&gt;</span>
    <span style="color:#f92672">&lt;name&gt;</span>fs.s3a.impl<span style="color:#f92672">&lt;/name&gt;</span>
    <span style="color:#f92672">&lt;value&gt;</span>org.apache.hadoop.fs.s3a.S3AFileSystem<span style="color:#f92672">&lt;/value&gt;</span>
    <span style="color:#f92672">&lt;description&gt;</span>The implementation class of the S3A Filesystem<span style="color:#f92672">&lt;/description&gt;</span>
  <span style="color:#f92672">&lt;/property&gt;</span>
<span style="color:#f92672">&lt;/configuration&gt;</span>
</code></pre></div><h2 id="get-started">Get started</h2>
<h3 id="spark-shell-on-csv-in-minios3">Spark Shell on CSV in Minio (S3)</h3>
<p><em>Note: Make sure JAVA_HOME has been set before setting up Spark Shell.</em></p>
<p><strong>Spark-Select</strong> can be integrated with Spark via <code>spark-shell</code>, <code>pyspark</code>, <code>spark-submit</code>, etc. You can also add it as Maven dependency, sbt-spark-package or a jar import.</p>
<p>Let&rsquo;s go through the steps below to use <code>spark-shell</code> in an example.</p>
<ul>
<li>
<p>Start Minio server and configure mc to interact with this server.</p>
</li>
<li>
<p>Create a bucket and upload a sample file : </p>
</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-sh" data-lang="sh"><span style="color:#75715e"># Downloading sample csv</span>
wget <span style="color:#e6db74">&#34;https://gist.github.com/raw/dc0d42feb6e8c816ed2ff1778b35a130/people.csv&#34;</span>
<span style="color:#75715e"># Creating a bucket named sjm-airlines</span>
mc mb data/sjm-airlines
<span style="color:#75715e"># Copying the csv to the created bucket using minio client</span>
mc cp people.csv data/sjm-airlines
</code></pre></div><ul>
<li>Download the sample scala code: </li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-sh" data-lang="sh">wget <span style="color:#e6db74">&#34;https://gist.github.com/raw/dc0d42feb6e8c816ed2ff1778b35a130/csv.scala&#34;</span>
</code></pre></div><ul>
<li>Downloading depedencies and adding it to spark : </li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-sh" data-lang="sh"><span style="color:#75715e"># Creating jars folder</span>
mkdir jars
<span style="color:#75715e"># Changing current directory to ./jars</span>
cd jars
<span style="color:#75715e"># Downloading jar dependencies</span>
wget http://central.maven.org/maven2/org/apache/hadoop/hadoop-aws/2.8.2/hadoop-aws-2.8.2.jar
wget http://central.maven.org/maven2/org/apache/httpcomponents/httpclient/4.5.3/httpclient-4.5.3.jar
wget http://central.maven.org/maven2/joda-time/joda-time/2.9.9/joda-time-2.9.9.jar
wget http://central.maven.org/maven2/com/amazonaws/aws-java-sdk-s3/1.11.524/aws-java-sdk-s3-1.11.524.jar
wget http://central.maven.org/maven2/com/amazonaws/aws-java-sdk-core/1.11.524/aws-java-sdk-core-1.11.524.jar
wget http://central.maven.org/maven2/com/amazonaws/aws-java-sdk/1.11.524/aws-java-sdk-1.11.524.jar
wget http://central.maven.org/maven2/com/amazonaws/aws-java-sdk-kms/1.11.524/aws-java-sdk-kms-1.11.524.jar
<span style="color:#75715e"># Copying all the jars to $SPARK_HOME/jars/</span>
cp *.jar $SPARK_HOME/jars/
</code></pre></div><ul>
<li>
<p>Configure Apache Spark with Minio. Detailed steps are available in <a href="https://github.com/minio/cookbook/blob/master/docs/apache-spark-with-minio.md">this document</a>.</p>
</li>
<li>
<p>Let&rsquo;s start <code>spark-shell</code> with the following command. To load some additional package later on, you can use <code>--packages</code> flag as well. </p>
</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-sh" data-lang="sh">$SPARK_HOME/bin/spark-shell --master local<span style="color:#f92672">[</span>4<span style="color:#f92672">]</span>
</code></pre></div><ul>
<li>After <code>spark-shell</code> is successfully invoked, load the <em>csv.scala</em>, and display the data:</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-scala" data-lang="scala"><span style="color:#a6e22e">Welcome</span> to
      <span style="color:#a6e22e">____</span>              <span style="color:#a6e22e">__</span>
     <span style="color:#f92672">/</span> <span style="color:#a6e22e">__/__</span>  <span style="color:#a6e22e">___</span> <span style="color:#a6e22e">_____</span><span style="color:#f92672">/</span> <span style="color:#f92672">/</span><span style="color:#a6e22e">__</span>
    <span style="color:#66d9ef">_</span>\ \<span style="color:#f92672">/</span> <span style="color:#66d9ef">_</span> \<span style="color:#f92672">/</span> <span style="color:#66d9ef">_</span> <span style="color:#960050;background-color:#1e0010">`</span><span style="color:#f92672">/</span> <span style="color:#a6e22e">__</span><span style="color:#f92672">/</span>  &#39;_/
   <span style="color:#f92672">/</span><span style="color:#a6e22e">___</span><span style="color:#f92672">/</span> <span style="color:#f92672">.</span><span style="color:#a6e22e">__/\</span><span style="color:#66d9ef">_</span><span style="color:#f92672">,</span><span style="color:#66d9ef">_</span><span style="color:#f92672">/</span><span style="color:#66d9ef">_</span><span style="color:#f92672">/</span> <span style="color:#f92672">/</span><span style="color:#66d9ef">_</span><span style="color:#f92672">/\</span><span style="color:#66d9ef">_</span>\   version <span style="color:#ae81ff">2.3</span><span style="color:#f92672">.</span><span style="color:#ae81ff">0</span>
      <span style="color:#f92672">/</span><span style="color:#66d9ef">_</span><span style="color:#f92672">/</span>

<span style="color:#a6e22e">Using</span> <span style="color:#a6e22e">Scala</span> version <span style="color:#ae81ff">2.</span><span style="color:#a6e22e">XX</span><span style="color:#f92672">.</span><span style="color:#a6e22e">XX</span> <span style="color:#f92672">(</span><span style="color:#a6e22e">Java</span> <span style="color:#a6e22e">HotSpot</span><span style="color:#f92672">(</span><span style="color:#a6e22e">TM</span><span style="color:#f92672">)</span> <span style="color:#ae81ff">64</span><span style="color:#f92672">-</span><span style="color:#a6e22e">Bit</span> <span style="color:#a6e22e">Server</span> <span style="color:#a6e22e">VM</span><span style="color:#f92672">,</span> <span style="color:#a6e22e">Java</span> <span style="color:#ae81ff">1.8</span><span style="color:#f92672">.</span><span style="color:#ae81ff">0</span><span style="color:#a6e22e">_XXX</span><span style="color:#f92672">)</span>
<span style="color:#a6e22e">Type</span> in expressions to have them evaluated<span style="color:#f92672">.</span>
<span style="color:#a6e22e">Type</span> <span style="color:#66d9ef">:</span><span style="color:#66d9ef">help</span> <span style="color:#66d9ef">for</span> <span style="color:#66d9ef">more</span> <span style="color:#66d9ef">information.</span>

<span style="color:#66d9ef">scala&gt;</span> <span style="color:#66d9ef">:load</span> <span style="color:#66d9ef">csv.scala</span>
<span style="color:#a6e22e">Loading</span> examples<span style="color:#f92672">/</span>csv<span style="color:#f92672">.</span>scala<span style="color:#f92672">...</span>
<span style="color:#66d9ef">import</span> org.apache.spark.sql._
<span style="color:#66d9ef">import</span> org.apache.spark.sql.types._
defined <span style="color:#66d9ef">object</span> <span style="color:#a6e22e">app</span>

scala<span style="color:#f92672">&gt;</span> app<span style="color:#f92672">.</span>main<span style="color:#f92672">(</span><span style="color:#a6e22e">Array</span><span style="color:#f92672">())</span>
<span style="color:#f92672">+-------+---+</span>
<span style="color:#f92672">|</span>   name<span style="color:#f92672">|</span>age<span style="color:#f92672">|</span>
<span style="color:#f92672">+-------+---+</span>
<span style="color:#f92672">|</span><span style="color:#a6e22e">Michael</span><span style="color:#f92672">|</span> <span style="color:#ae81ff">31</span><span style="color:#f92672">|</span>
<span style="color:#f92672">|</span>   <span style="color:#a6e22e">Andy</span><span style="color:#f92672">|</span> <span style="color:#ae81ff">30</span><span style="color:#f92672">|</span>
<span style="color:#f92672">|</span> <span style="color:#a6e22e">Justin</span><span style="color:#f92672">|</span> <span style="color:#ae81ff">19</span><span style="color:#f92672">|</span>
<span style="color:#f92672">+-------+---+</span>

<span style="color:#f92672">+-------+---+</span>
<span style="color:#f92672">|</span>   name<span style="color:#f92672">|</span>age<span style="color:#f92672">|</span>
<span style="color:#f92672">+-------+---+</span>
<span style="color:#f92672">|</span><span style="color:#a6e22e">Michael</span><span style="color:#f92672">|</span> <span style="color:#ae81ff">31</span><span style="color:#f92672">|</span>
<span style="color:#f92672">|</span>   <span style="color:#a6e22e">Andy</span><span style="color:#f92672">|</span> <span style="color:#ae81ff">30</span><span style="color:#f92672">|</span>
<span style="color:#f92672">+-------+---+</span>
scala<span style="color:#f92672">&gt;</span>
</code></pre></div><p><img src="/images/data-analysis/1.jpg" alt="Scala UI"></p>
<p>You can see that out of 3 entries, we could use SQL-like query to only select those
entries with age &gt; 19.</p>
<p>Awesome, you have successfully set up Spark! Let&rsquo;s proceed futher.</p>
<h3 id="spark-shell-using-pyspark-andminio">Spark-Shell using PySpark and Minio</h3>
<p>Make sure all of the <code>aws-java-sdk</code> jars are present under <code>$SPARK_HOME/jars/</code> or
added to the <code>spark.jars.packages</code> in <em>spark-defaults.conf</em> file, before proceeding.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-sh" data-lang="sh"><span style="color:#75715e"># Running pyspark from Spark_Home Binary</span>
$SPARK_HOME/bin/pyspark
<span style="color:#e6db74">``</span>

You should see the following screen :

<span style="color:#e6db74">```</span>python
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _<span style="color:#ae81ff">\ \/</span> _ <span style="color:#ae81ff">\/</span> _ <span style="color:#e6db74">`</span>/ __/  <span style="color:#e6db74">&#39;_/
</span><span style="color:#e6db74">   /__ / .__/\_,_/_/ /_/\_\   version 2.3.0
</span><span style="color:#e6db74">      /_/
</span><span style="color:#e6db74">
</span><span style="color:#e6db74">Using Python version 2.7.12 (default, Nov 12 2018 14:36:49)
</span><span style="color:#e6db74">SparkSession available as &#39;</span>spark<span style="color:#960050;background-color:#1e0010">&#39;</span>.
&gt;&gt;&gt;
</code></pre></div><p>Let&rsquo;s execute the commands following lines to verify the same as in <code>scala-shell</code> can be achieved in <em>PySpark</em>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">&gt;&gt;&gt;</span> <span style="color:#f92672">from</span> pyspark.sql.types <span style="color:#f92672">import</span> <span style="color:#f92672">*</span>
<span style="color:#f92672">&gt;&gt;&gt;</span> df <span style="color:#f92672">=</span> spark<span style="color:#f92672">.</span>read<span style="color:#f92672">.</span>format(<span style="color:#e6db74">&#34;csv&#34;</span>)<span style="color:#f92672">.</span>option(<span style="color:#e6db74">&#34;header&#34;</span>, <span style="color:#e6db74">&#34;true&#34;</span>)<span style="color:#f92672">.</span>load(<span style="color:#e6db74">&#34;s3a://sjm-airlines/people.csv&#34;</span>)
<span style="color:#f92672">&gt;&gt;&gt;</span> df<span style="color:#f92672">.</span>show()
<span style="color:#f92672">+-------+---+</span>
<span style="color:#f92672">|</span>   name<span style="color:#f92672">|</span>age<span style="color:#f92672">|</span>
<span style="color:#f92672">+-------+---+</span>
<span style="color:#f92672">|</span>Michael<span style="color:#f92672">|</span> <span style="color:#ae81ff">31</span><span style="color:#f92672">|</span>
<span style="color:#f92672">|</span>   Andy<span style="color:#f92672">|</span> <span style="color:#ae81ff">30</span><span style="color:#f92672">|</span>
<span style="color:#f92672">|</span> Justin<span style="color:#f92672">|</span> <span style="color:#ae81ff">19</span><span style="color:#f92672">|</span>
<span style="color:#f92672">+-------+---+</span>
<span style="color:#f92672">&gt;&gt;&gt;</span> df<span style="color:#f92672">.</span>select(<span style="color:#e6db74">&#34;*&#34;</span>)<span style="color:#f92672">.</span>filter(<span style="color:#e6db74">&#34;age &gt; 19&#34;</span>)<span style="color:#f92672">.</span>show()
<span style="color:#f92672">+-------+---+</span>
<span style="color:#f92672">|</span>   name<span style="color:#f92672">|</span>age<span style="color:#f92672">|</span>
<span style="color:#f92672">+-------+---+</span>
<span style="color:#f92672">|</span>Michael<span style="color:#f92672">|</span> <span style="color:#ae81ff">31</span><span style="color:#f92672">|</span>
<span style="color:#f92672">|</span>   Andy<span style="color:#f92672">|</span> <span style="color:#ae81ff">30</span><span style="color:#f92672">|</span>
<span style="color:#f92672">+-------+---+</span>
</code></pre></div><h3 id="connect-minio-and-spark-with-jupyternotebook">Connect Minio and Spark with Jupyter Notebook</h3>
<p>Follow the steps below to set up Jupyter:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-sh" data-lang="sh"><span style="color:#75715e"># Downloading shell script to install Jupyter using Anaconda</span>
wget https://repo.anaconda.com/archive/Anaconda3-2018.12-Linux-x86_64.sh
<span style="color:#75715e"># Making the shell script executable</span>
chmod +x ./Anaconda3-2018.12-Linux-x86_64.sh
<span style="color:#75715e"># Running the shell script with bash</span>
bash Anaconda3-2018.12-Linux-x86_64.sh
<span style="color:#75715e"># Create new conda environment with minimal environment with only python installed.</span>
conda create -n myconda python<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>
<span style="color:#75715e"># Put your self inside this environment run</span>
conda activate myconda
<span style="color:#75715e"># Verify the Anaconda Python v3.x Terminal inside the environment. To exit, press CTRL+D or `exit()`</span>
python
<span style="color:#75715e"># Install Jupyter Notebook inside the environment</span>
conda install jupyter
<span style="color:#75715e"># Install findspark inside the environment using conda-forge channel</span>
conda install -c conda-forge findspark
<span style="color:#75715e"># (Optional) Setting up jupyter notebook password, enter the desired password (If not set, have to use randomly generated tokens each time)</span>
jupyter notebook password
<span style="color:#75715e"># Running Jupyter Notebook and making it available to public at port 8888</span>
jupyter notebook --ip 0.0.0.0  --port <span style="color:#ae81ff">8888</span>
</code></pre></div><p>You should be seeing the following, if everything goes well :</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-sh" data-lang="sh"><span style="color:#f92672">[</span>I 06:50:01.156 NotebookApp<span style="color:#f92672">]</span> JupyterLab extension loaded from /home/prashant/anaconda3/lib/python3.7/site-packages/jupyterlab
<span style="color:#f92672">[</span>I 06:50:01.157 NotebookApp<span style="color:#f92672">]</span> JupyterLab application directory is /home/prashant/anaconda3/share/jupyter/lab
<span style="color:#f92672">[</span>I 06:50:01.158 NotebookApp<span style="color:#f92672">]</span> Serving notebooks from local directory: /home/prashant
<span style="color:#f92672">[</span>I 06:50:01.158 NotebookApp<span style="color:#f92672">]</span> The Jupyter Notebook is running at:
<span style="color:#f92672">[</span>I 06:50:01.158 NotebookApp<span style="color:#f92672">]</span> http://<span style="color:#f92672">(</span>instance-1 or 127.0.0.1<span style="color:#f92672">)</span>:8888/
<span style="color:#f92672">[</span>I 06:50:01.158 NotebookApp<span style="color:#f92672">]</span> Use Control-C to stop this server and shut down all kernels <span style="color:#f92672">(</span>twice to skip confirmation<span style="color:#f92672">)</span>.
</code></pre></div><h3 id="deactivate-conda-virtual-environment">Deactivate Conda virtual environment</h3>
<p>Example:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-sh" data-lang="sh"><span style="color:#75715e"># Usage: conda deactivate &lt;environment-name&gt;</span>
conda deactivate myconda
</code></pre></div><h3 id="converting-python-scriptspy-file-to-jupyter-notebookipynb-file">Converting python scripts(.py) file to Jupyter notebook(.ipynb) file</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-sh" data-lang="sh"><span style="color:#75715e"># Installing p2j using python-pip</span>
pip install p2j
</code></pre></div><p>Example:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-sh" data-lang="sh"><span style="color:#75715e"># Generating .ipynb file out of some sample script.py using p2j</span>
p2j script.py
</code></pre></div><h3 id="converting-jupiter-notebookipynb-file-to-python-scriptspy-file">Converting Jupiter notebook(.ipynb) file to python scripts(.py) file</h3>
<p>You can make use of nbconvert that comes along with Jupiter. Example:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-sh" data-lang="sh"><span style="color:#75715e"># Generating script.py file out of some sample .ipynb file using jupyter nbconvert</span>
jupyter nbconvert script.ipynb
</code></pre></div><h3 id="creating-a-sample-pythonfile">Creating a sample python file</h3>
<p>Let&rsquo;s create a python file spark-minio.py with the codes below :</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># Import sys and print the python environment</span>
<span style="color:#f92672">import</span> sys
print(sys<span style="color:#f92672">.</span>executable)
<span style="color:#75715e"># Import findspark to find spark make it accessible at run time</span>
<span style="color:#f92672">import</span> findspark
findspark<span style="color:#f92672">.</span>init()
<span style="color:#75715e"># Import pyspark and its components</span>
<span style="color:#f92672">import</span> pyspark
<span style="color:#f92672">from</span> pyspark.sql.types <span style="color:#f92672">import</span> <span style="color:#f92672">*</span>
<span style="color:#f92672">from</span> pyspark.sql <span style="color:#f92672">import</span> SparkSession

<span style="color:#75715e"># Creating SparkSession</span>
spark <span style="color:#f92672">=</span> SparkSession<span style="color:#f92672">.</span>builder<span style="color:#f92672">.</span>getOrCreate()
<span style="color:#75715e"># Creating schema of the CSV fields</span>
schema <span style="color:#f92672">=</span> StructType([StructField(<span style="color:#e6db74">&#39;name&#39;</span>, StringType(), <span style="color:#66d9ef">True</span>),StructField(<span style="color:#e6db74">&#39;age&#39;</span>, IntegerType(), <span style="color:#66d9ef">True</span>)])
<span style="color:#75715e"># Creating a dataframe from a csv in S3</span>
df <span style="color:#f92672">=</span> spark<span style="color:#f92672">.</span>read<span style="color:#f92672">.</span>format(<span style="color:#e6db74">&#34;csv&#34;</span>)<span style="color:#f92672">.</span>option(<span style="color:#e6db74">&#34;header&#34;</span>, <span style="color:#e6db74">&#34;true&#34;</span>)<span style="color:#f92672">.</span>load(<span style="color:#e6db74">&#34;s3a://sjm-airlines/people.csv&#34;</span>)
<span style="color:#75715e"># Displaying all data in the CSV</span>
df<span style="color:#f92672">.</span>show()
<span style="color:#75715e"># Displaying all the data in the csv for which age is greater than 19</span>
df<span style="color:#f92672">.</span>select(<span style="color:#e6db74">&#34;*&#34;</span>)<span style="color:#f92672">.</span>filter(<span style="color:#e6db74">&#34;age &gt; 19&#34;</span>)<span style="color:#f92672">.</span>show()
</code></pre></div><p>Now, converting the python code(spark-minio.py) to jupyter notebook compatible file (.ipynb) :</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-sh" data-lang="sh"><span style="color:#75715e"># Generating spark-minio.ipynb file out of spark-minio.py</span>
p2j spark-minio.py
</code></pre></div><h3 id="runningipynb-file-from-the-jupyter-notebookui">Running .ipynb file from the Jupyter notebook UI</h3>
<p>Let&rsquo;s open the UI running at http://(server-public-ip-address/localhost):8888/.
Enter the jupyter notebok password (or the token) and then, you should be seeing something like this :</p>
<p><img src="/images/data-analysis/2.jpg" alt="Jupyter Notebook UI"></p>
<p>Select spark-minio.ipynb file and click on run, if everything went right, you should be getting the screen below :</p>
<p><img src="/images/data-analysis/3.jpg" alt="Jupyter Notebook - loading people.csv"></p>
<p>Running Some Live Examples
 Before running the example, let&rsquo;s get compress the sample csv file with gzip compression.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-sh" data-lang="sh"><span style="color:#75715e"># Generating gzip file named people.csv.gz file out of people.csv, while keeping the original file with -k flag</span>
gzip -k people.csv
<span style="color:#75715e"># Copying the csv.gz file to the bucket using minio client</span>
mc cp people.csv.gz data/sjm-airlines
</code></pre></div><p> In Jupyter Notebook, go to File Tab &gt; New Notebook &gt; Python 3 (Or any other kernel). Try the following pyspark example on the data present in Minio. Note that the gzip compression is automatically detected with the .gz extension and handled when loading it with Spark&rsquo;s native csv format.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> findspark
findspark<span style="color:#f92672">.</span>init()
<span style="color:#f92672">import</span> pyspark
<span style="color:#f92672">from</span> pyspark.sql.types <span style="color:#f92672">import</span> <span style="color:#f92672">*</span>
<span style="color:#f92672">from</span> pyspark.sql <span style="color:#f92672">import</span> SparkSession
spark <span style="color:#f92672">=</span> SparkSession<span style="color:#f92672">.</span>builder<span style="color:#f92672">.</span>getOrCreate()
schema <span style="color:#f92672">=</span> StructType([StructField(<span style="color:#e6db74">&#39;name&#39;</span>, StringType(), <span style="color:#66d9ef">True</span>),StructField(<span style="color:#e6db74">&#39;age&#39;</span>, IntegerType(), <span style="color:#66d9ef">True</span>)])
df <span style="color:#f92672">=</span> spark<span style="color:#f92672">.</span>read<span style="color:#f92672">.</span>format(<span style="color:#e6db74">&#34;csv&#34;</span>)<span style="color:#f92672">.</span>option(<span style="color:#e6db74">&#34;header&#34;</span>, <span style="color:#e6db74">&#34;true&#34;</span>)<span style="color:#f92672">.</span>load(<span style="color:#e6db74">&#34;s3a://sjm-airlines/people.csv.gz&#34;</span>)
df<span style="color:#f92672">.</span>createOrReplaceTempView(<span style="color:#e6db74">&#34;people&#34;</span>)
print(<span style="color:#e6db74">&#34;List of all people :&#34;</span>)
df2<span style="color:#f92672">.</span>show()
print(<span style="color:#e6db74">&#34;People with age less than 20 :&#34;</span>)
df2 <span style="color:#f92672">=</span> spark<span style="color:#f92672">.</span>sql(<span style="color:#e6db74">&#34;SELECT * FROM people where age&gt;20&#34;</span>)
df2<span style="color:#f92672">.</span>show()
</code></pre></div><p> If the steps are properly followed, you should be seeing the following in the jupyter notebook:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-sh" data-lang="sh">List of all people :
+-------+---+
|   name|age|
+-------+---+
|Michael| 31|
|   Andy| 30|
+-------+---+

People with age less than <span style="color:#ae81ff">20</span> :
+-------+---+
|   name|age|
+-------+---+
|Michael| 31|
|   Andy| 30|
+-------+---+
</code></pre></div><p> For the next example, we are gonna use SQL query capability of Spark dataframe on comparatively big CSV with 13 header fields and 2000251 entries. For the task, at first, we are gonna download the CSV with gzipped compression from the following link.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-sh" data-lang="sh">wget https://gist.github.com/raw/d65254b1ac4b64c5969bd6309d8f8424/natality00.gz
</code></pre></div><p>Schema of the CSV and the description of each field can be found <a href="https://gist.github.com/raw/d65254b1ac4b64c5969bd6309d8f8424/natality-0-schema.md">HERE</a>.
 Create a new bucket in Minio, here, we are naming the bucket spark-experiment and upload the downloaded file to that bucket.
 You can use Minio UI for the task. Or, you can use Minio Client - mc for the same.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-sh" data-lang="sh"><span style="color:#75715e"># Go to the `data` folder which Minio Server is pointing to </span>
cd ~/data
<span style="color:#75715e"># Creating a new bucket</span>
mc mb spark-experiment
<span style="color:#75715e"># Copying the compressed file inside the bucket</span>
mc cp ../natality00.gz spark-experiment
</code></pre></div><p> Now, let&rsquo;s try the following script in Jupyter notebook. You can either create a new cell in the same old notebook or create a new notebook for running the script. </p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> findspark
findspark<span style="color:#f92672">.</span>init()
<span style="color:#f92672">import</span> pyspark
<span style="color:#f92672">from</span> pyspark.sql.types <span style="color:#f92672">import</span> <span style="color:#f92672">*</span>
<span style="color:#f92672">from</span> pyspark.context <span style="color:#f92672">import</span> SparkContext
<span style="color:#f92672">from</span> pyspark.sql.session <span style="color:#f92672">import</span> SparkSession

sc <span style="color:#f92672">=</span> SparkContext<span style="color:#f92672">.</span>getOrCreate()
spark <span style="color:#f92672">=</span> SparkSession(sc)

df <span style="color:#f92672">=</span> spark<span style="color:#f92672">.</span>read<span style="color:#f92672">.</span>format(<span style="color:#e6db74">&#34;csv&#34;</span>)<span style="color:#f92672">.</span>option(<span style="color:#e6db74">&#34;header&#34;</span>, <span style="color:#e6db74">&#34;true&#34;</span>)<span style="color:#f92672">.</span>load(<span style="color:#e6db74">&#34;s3a://spark-experiment/natality00.gz&#34;</span>)
query<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;SELECT is_male, count(*) as count, AVG(weight_pounds) AS avg_weight FROM natality GROUP BY is_male&#34;</span>
df<span style="color:#f92672">.</span>createOrReplaceTempView(<span style="color:#e6db74">&#34;natality&#34;</span>)
df2 <span style="color:#f92672">=</span> spark<span style="color:#f92672">.</span>sql(query)
df2<span style="color:#f92672">.</span>show()
</code></pre></div><p>Upon running the script in the notebook, you should get the following output:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">+-------+-------+-----------------+</span>
<span style="color:#f92672">|</span>is_male<span style="color:#f92672">|</span>  count<span style="color:#f92672">|</span>       avg_weight<span style="color:#f92672">|</span>
<span style="color:#f92672">+-------+-------+-----------------+</span>
<span style="color:#f92672">|</span>  false<span style="color:#f92672">|</span> <span style="color:#ae81ff">975147</span><span style="color:#f92672">|</span> <span style="color:#ae81ff">7.17758067338709</span><span style="color:#f92672">|</span>
<span style="color:#f92672">|</span>   true<span style="color:#f92672">|</span><span style="color:#ae81ff">1025104</span><span style="color:#f92672">|</span><span style="color:#ae81ff">7.439839161360215</span><span style="color:#f92672">|</span>
<span style="color:#f92672">+-------+-------+-----------------+</span>
</code></pre></div><p>Visualization with charts and graphs using Pandas
Installation
 Install Pandas using conda. PySpark dataframe requires pandas &gt;= 0.19.2 for executing any of the features by pandas.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-sh" data-lang="sh"><span style="color:#75715e"># Installing pandas and matplotlib. Make sure inside the created conda virtual environment, when you are running the following command</span>
conda install pandas matplotlib
</code></pre></div><h2 id="reports-and-observations">Reports and Observations</h2>
<h3 id="report-1">Report 1</h3>
<p>Let&rsquo;s display some charts on the report that we got in the previous example. Let&rsquo;s create a new cell on the same notebook rather than integrating the following snippet in the above code, to reduce the time to plot multiple charts on the same report.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">df3 <span style="color:#f92672">=</span> df2<span style="color:#f92672">.</span>toPandas()
df3<span style="color:#f92672">.</span>plot(x<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;is_male&#39;</span>, y<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;count&#39;</span>, kind<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;bar&#39;</span>)
df3<span style="color:#f92672">.</span>plot(x<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;is_male&#39;</span>, y<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;avg_weight&#39;</span>, kind<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;bar&#39;</span>)
</code></pre></div><p><img src="/images/data-analysis/4.jpg" alt="Example 1 - gender vs count"> <img src="/images/data-analysis/5.jpg" alt="Example 1 - gender vs average weight">
<em>Chart Graph of Is_Male Boolean VS Count and Average weight</em></p>
<p><strong>Observation</strong>: From the generated chart, we can observe that gender of the child doesn&rsquo;t
have any significant role neither in the average weight of the child nor wide difference
can be seen in a total count of the two gender divisions.</p>
<h3 id="report-2">Report 2</h3>
<p>Now, let us try another example. Let&rsquo;s create a new notebook for this. If you don&rsquo;t wish
to create a new one, you can try on a new cell of the previous notebook.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> findspark
findspark<span style="color:#f92672">.</span>init()
<span style="color:#f92672">import</span> pyspark
<span style="color:#f92672">from</span> pyspark.sql.types <span style="color:#f92672">import</span> <span style="color:#f92672">*</span>

<span style="color:#f92672">from</span> pyspark.context <span style="color:#f92672">import</span> SparkContext
<span style="color:#f92672">from</span> pyspark.sql.session <span style="color:#f92672">import</span> SparkSession
sc <span style="color:#f92672">=</span> SparkContext<span style="color:#f92672">.</span>getOrCreate()
spark <span style="color:#f92672">=</span> SparkSession(sc)

df <span style="color:#f92672">=</span> spark<span style="color:#f92672">.</span>read<span style="color:#f92672">.</span>format(<span style="color:#e6db74">&#34;csv&#34;</span>)<span style="color:#f92672">.</span>option(<span style="color:#e6db74">&#34;header&#34;</span>, <span style="color:#e6db74">&#34;true&#34;</span>)<span style="color:#f92672">.</span>load(<span style="color:#e6db74">&#34;s3a://spark-experiment/natality00.gz&#34;</span>)
query<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;SELECT mother_age, count(*) as count, AVG(weight_pounds) AS avg_weight FROM natality GROUP BY mother_age&#34;</span>
df<span style="color:#f92672">.</span>createOrReplaceTempView(<span style="color:#e6db74">&#34;natality&#34;</span>)
print(<span style="color:#e6db74">&#34;Based on mother_age, total count and average weight is as follow : &#34;</span>)
df2 <span style="color:#f92672">=</span> spark<span style="color:#f92672">.</span>sql(query)
df3 <span style="color:#f92672">=</span> df2<span style="color:#f92672">.</span>toPandas()
df4<span style="color:#f92672">=</span> df3<span style="color:#f92672">.</span>sort_values(<span style="color:#e6db74">&#39;mother_age&#39;</span>)
print(<span style="color:#e6db74">&#34;***DONE***&#34;</span>)
</code></pre></div><p>After running the program, when it prints DONE. Create a new cell below and run the following snippet:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">df4<span style="color:#f92672">.</span>plot(x<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;mother_age&#39;</span>, y<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;count&#39;</span>)
df4<span style="color:#f92672">.</span>plot(x<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;mother_age&#39;</span>, y<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;avg_weight&#39;</span>)data
</code></pre></div><p><img src="/images/data-analysis/6.jpg" alt="Example 2 - mother age vs count"> <img src="/images/data-analysis/7.jpg" alt="Example 2 - mother age vs average weight">
<em>Chart Graph of Mother Age VS Count and Average weight</em></p>
<p><strong>Observation</strong> : We can observe that most of the mothers are between 20–30 age range when
they gave birth. While the average weight of the children shows some decline in case of mothers at a young
age, it shows a significant decrease in children&rsquo;s average weight in case of mothers at old age.</p>
<h3 id="report-3">Report 3</h3>
<p>This one will be an interesting one. We will plot a chart with a scatter graph.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> findspark
findspark<span style="color:#f92672">.</span>init()
<span style="color:#f92672">import</span> pyspark
<span style="color:#f92672">from</span> pyspark.sql.types <span style="color:#f92672">import</span> <span style="color:#f92672">*</span>

<span style="color:#f92672">from</span> pyspark.context <span style="color:#f92672">import</span> SparkContext
<span style="color:#f92672">from</span> pyspark.sql.session <span style="color:#f92672">import</span> SparkSession
sc <span style="color:#f92672">=</span> SparkContext<span style="color:#f92672">.</span>getOrCreate()
spark <span style="color:#f92672">=</span> SparkSession(sc)

df <span style="color:#f92672">=</span> spark<span style="color:#f92672">.</span>read<span style="color:#f92672">.</span>format(<span style="color:#e6db74">&#34;csv&#34;</span>)<span style="color:#f92672">.</span>option(<span style="color:#e6db74">&#34;header&#34;</span>, <span style="color:#e6db74">&#34;true&#34;</span>)<span style="color:#f92672">.</span>load(<span style="color:#e6db74">&#34;s3a://spark-experiment/natality00.gz&#34;</span>)
query<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;SELECT INT(gestation_weeks), COUNT(*) AS count, AVG(weight_pounds) AS avg_weight FROM natality GROUP BY gestation_weeks&#34;</span>
df<span style="color:#f92672">.</span>createOrReplaceTempView(<span style="color:#e6db74">&#34;natality&#34;</span>)
print(<span style="color:#e6db74">&#34;Based on gestation_weeks, total count and average weight is as follow : &#34;</span>)
df2 <span style="color:#f92672">=</span> spark<span style="color:#f92672">.</span>sql(query)
df3 <span style="color:#f92672">=</span> df2<span style="color:#f92672">.</span>toPandas()
df4<span style="color:#f92672">=</span> df3<span style="color:#f92672">.</span>sort_values(<span style="color:#e6db74">&#39;gestation_weeks&#39;</span>)
print(<span style="color:#e6db74">&#34;***DONE***&#34;</span>)
</code></pre></div><p> Like we did before, after DONE is printed. Create a new cell below with the following snippet.
Here, we are introducing matplotlib&rsquo;s axes object(ax), and dataframe.describe().</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#66d9ef">as</span> plt
fig, ax <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>subplots()
df4<span style="color:#f92672">.</span>plot(kind<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;scatter&#34;</span>, x<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;gestation_weeks&#34;</span>, y<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;avg_weight&#34;</span>, s<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span>, c<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;count&#34;</span>, cmap<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;RdYlGn&#34;</span>, ax<span style="color:#f92672">=</span>ax)
df4<span style="color:#f92672">.</span>describe()
</code></pre></div><p><img src="/images/data-analysis/8.jpg" alt="Example 3 - gestation week vs count"> <img src="/images/data-analysis/9.jpg" alt="Example 3 - gestation week vs average weight">
<em>Scatter Graph and Data Frame Description of Gestation week VS Count and Average weight</em></p>
<p><strong>Observation</strong>: From the scatter graph, it can be seen that the maximum number of mothers'
gestation period was 40 weeks and children born around this period are mostly of more
weight than rest. It can be seen that there are around 100k entries for which <code>gestation_weeks</code>
is 99, which is not possible in reality. So, it can be concluded that 99 is the dummy
value present for those whose gestation period data wasn&rsquo;t available.</p>
<p><em>Note: List of possible cmap i.e. colormap can be found <a href="https://gist.github.com/ab86e34febe7dba1d05bf0b2b7f56611">here</a>.</em></p>
<hr>
<ul class="pa0 mb0">
  
   <li class="list" style="display:inline;">
     <a href="/tags/apache-spark" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">apache spark</a>
   </li>
  
   <li class="list" style="display:inline;">
     <a href="/tags/big-data" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">big data</a>
   </li>
  
   <li class="list" style="display:inline;">
     <a href="/tags/data-analysis" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">data analysis</a>
   </li>
  
   <li class="list" style="display:inline;">
     <a href="/tags/jupyter-notebook" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">jupyter notebook</a>
   </li>
  
   <li class="list" style="display:inline;">
     <a href="/tags/minio" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">minio</a>
   </li>
  
   <li class="list" style="display:inline;">
     <a href="/tags/pandas" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">pandas</a>
   </li>
  
</ul>
<div class="mt6 instapaper_ignoref">
      
        <div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "prashantshahi" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
      
      
      </div>
    </div>

    <aside class="w-30-l mt6-l"><div class="bg-light-gray pa3 nested-list-reset nested-copy-line-height nested-links">
    <p class="f5 b mb3">What&#39;s in this blog</p>
      <nav id="TableOfContents">
  <ul>
    <li><a href="#brief-overview-of-the-components">Brief Overview of the components</a></li>
    <li><a href="#setup">Setup</a>
      <ul>
        <li><a href="#system-configuration-vminstance">System configuration (VM/Instance)</a></li>
        <li><a href="#downloading-minio-server-andclient">Downloading Minio Server and Client</a></li>
        <li><a href="#minio-client">Minio Client</a></li>
        <li><a href="#loading-sampledata">Loading Sample Data</a></li>
        <li><a href="#setting-up-java-environment-for-sparkshell">Setting up Java Environment for Spark Shell</a></li>
        <li><a href="#installation-of-apache-spark-andhadoop">Installation of Apache Spark and Hadoop</a></li>
        <li><a href="#setting-up-minio-server-endpoint-and-credentials">Setting up Minio Server endpoint and credentials</a></li>
      </ul>
    </li>
    <li><a href="#get-started">Get started</a>
      <ul>
        <li><a href="#spark-shell-on-csv-in-minios3">Spark Shell on CSV in Minio (S3)</a></li>
        <li><a href="#spark-shell-using-pyspark-andminio">Spark-Shell using PySpark and Minio</a></li>
        <li><a href="#connect-minio-and-spark-with-jupyternotebook">Connect Minio and Spark with Jupyter Notebook</a></li>
        <li><a href="#deactivate-conda-virtual-environment">Deactivate Conda virtual environment</a></li>
        <li><a href="#converting-python-scriptspy-file-to-jupyter-notebookipynb-file">Converting python scripts(.py) file to Jupyter notebook(.ipynb) file</a></li>
        <li><a href="#converting-jupiter-notebookipynb-file-to-python-scriptspy-file">Converting Jupiter notebook(.ipynb) file to python scripts(.py) file</a></li>
        <li><a href="#creating-a-sample-pythonfile">Creating a sample python file</a></li>
        <li><a href="#runningipynb-file-from-the-jupyter-notebookui">Running .ipynb file from the Jupyter notebook UI</a></li>
      </ul>
    </li>
    <li><a href="#reports-and-observations">Reports and Observations</a>
      <ul>
        <li><a href="#report-1">Report 1</a></li>
        <li><a href="#report-2">Report 2</a></li>
        <li><a href="#report-3">Report 3</a></li>
      </ul>
    </li>
  </ul>
</nav>
  </div>




</aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="https://prashantshahi.dev" >
    &copy;  prashantshahi.dev 2022 
  </a>
    <div>




<a href="https://twitter.com/c0degeas" target="_blank" class="link-transition twitter link dib z-999 pt3 pt0-l mr1" title="Twitter link" rel="noopener" aria-label="follow on Twitter——Opens in a new window">
  <svg height="32px"  style="enable-background:new 0 0 67 67;" version="1.1" viewBox="0 0 67 67" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M37.167,22.283c-2.619,0.953-4.274,3.411-4.086,6.101  l0.063,1.038l-1.048-0.127c-3.813-0.487-7.145-2.139-9.974-4.915l-1.383-1.377l-0.356,1.017c-0.754,2.267-0.272,4.661,1.299,6.271  c0.838,0.89,0.649,1.017-0.796,0.487c-0.503-0.169-0.943-0.296-0.985-0.233c-0.146,0.149,0.356,2.076,0.754,2.839  c0.545,1.06,1.655,2.097,2.871,2.712l1.027,0.487l-1.215,0.021c-1.173,0-1.215,0.021-1.089,0.467  c0.419,1.377,2.074,2.839,3.918,3.475l1.299,0.444l-1.131,0.678c-1.676,0.976-3.646,1.526-5.616,1.568  C19.775,43.256,19,43.341,19,43.405c0,0.211,2.557,1.397,4.044,1.864c4.463,1.377,9.765,0.783,13.746-1.568  c2.829-1.673,5.657-5,6.978-8.221c0.713-1.716,1.425-4.851,1.425-6.354c0-0.975,0.063-1.102,1.236-2.267  c0.692-0.678,1.341-1.419,1.467-1.631c0.21-0.403,0.188-0.403-0.88-0.043c-1.781,0.636-2.033,0.551-1.152-0.402  c0.649-0.678,1.425-1.907,1.425-2.267c0-0.063-0.314,0.042-0.671,0.233c-0.377,0.212-1.215,0.53-1.844,0.72l-1.131,0.361l-1.027-0.7  c-0.566-0.381-1.361-0.805-1.781-0.932C39.766,21.902,38.131,21.944,37.167,22.283z M33,64C16.432,64,3,50.569,3,34S16.432,4,33,4  s30,13.431,30,30S49.568,64,33,64z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/></svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>




<a href="https://www.linkedin.com/in/prashantshahi" target="_blank" class="link-transition linkedin link dib z-999 pt3 pt0-l mr1" title="LinkedIn link" rel="noopener" aria-label="follow on LinkedIn——Opens in a new window">
  <svg  height="32px"  style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>


<a href="https://gitlab.com/prashant-shahi" target="_blank" class="link-transition github link dib z-999 pt3 pt0-l mr1" title="Github link" rel="noopener" aria-label="follow on Github——Opens in a new window">
  <svg  height="32px"  style="enable-background:new 0 0 512 512;" version="1.1" viewBox="0 0 512 512" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
  <path d="M256,32C132.3,32,32,134.8,32,261.7c0,101.5,64.2,187.5,153.2,217.9c11.2,2.1,15.3-5,15.3-11.1   c0-5.5-0.2-19.9-0.3-39.1c-62.3,13.9-75.5-30.8-75.5-30.8c-10.2-26.5-24.9-33.6-24.9-33.6c-20.3-14.3,1.5-14,1.5-14   c22.5,1.6,34.3,23.7,34.3,23.7c20,35.1,52.4,25,65.2,19.1c2-14.8,7.8-25,14.2-30.7c-49.7-5.8-102-25.5-102-113.5   c0-25.1,8.7-45.6,23-61.6c-2.3-5.8-10-29.2,2.2-60.8c0,0,18.8-6.2,61.6,23.5c17.9-5.1,37-7.6,56.1-7.7c19,0.1,38.2,2.6,56.1,7.7   c42.8-29.7,61.5-23.5,61.5-23.5c12.2,31.6,4.5,55,2.2,60.8c14.3,16.1,23,36.6,23,61.6c0,88.2-52.4,107.6-102.3,113.3   c8,7.1,15.2,21.1,15.2,42.5c0,30.7-0.3,55.5-0.3,63c0,6.1,4,13.3,15.4,11C415.9,449.1,480,363.1,480,261.7   C480,134.8,379.7,32,256,32z"/>
</svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>



<a href="https://keybase.io/prashant_s" target="_blank" class="link-transition keybase link dib z-999 pt3 pt0-l mr1" title="Keybase link" rel="noopener" aria-label="follow on Keybase——Opens in a new window">
  <svg  height="32px"  style="enable-background:new 0 0 33 33;" version="1.1" viewBox="0 0 33 33" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
    <path d="M16.1477825,0.840201442 C7.31178255,0.840201442 0.147782547,8.00420144 0.147782547,16.8402014 C0.147782547,25.6762014 7.31178255,32.8402014 16.1477825,32.8402014 C24.9837825,32.8402014 32.1477825,25.6762014 32.1477825,16.8402014 C32.1477825,8.00420144 24.9837825,0.840201442 16.1477825,0.840201442 Z M14.533,26.371 C14.533,26.899 14.105,27.324 13.579,27.324 C13.054,27.324 12.625,26.899 12.625,26.371 C12.625,25.845 13.053,25.417 13.578,25.417 C14.102,25.417 14.529,25.848 14.529,26.372 M14.75,5 L15.957,5.71 C15.361,6.981 15.428,7.453 15.461,7.558 C15.942,7.544 16.516,7.647 17.172,7.863 C18.254,8.223 19.119,8.988 19.61,10.023 C20.097,11.055 20.14,12.214 19.73,13.278 C19.719,13.306 19.707,13.334 19.695,13.361 L19.695,13.361 L19.925,13.439 C21.375,13.957 22.72,14.804 23.88,15.943 C23.898,15.962 23.915,15.978 23.93,15.996 L23.93,15.996 L24.065,16.127 L24.156,16.226 L24.232,16.306 C24.342,16.426 24.447,16.545 24.551,16.665 C24.598,16.721 24.647,16.773 24.692,16.834 C24.739,16.893 24.789,16.949 24.835,17.009 L24.835,17.009 L24.991,17.213 C26.389,19.066 27.174,21.288 27.175,23.487 C27.175,25.567 26.77,27.436 25.994,28.999 L25.994,28.999 L24.383,28.999 C25.508,27.174 25.763,25.05 25.763,23.487 C25.763,22.989 25.713,22.489 25.622,21.991 L25.622,21.991 L25.518,22.156 C24.605,23.452 22.85,23.945 21.045,23.413 C16.879,22.192 13.21,22.708 10.135,24.942 L10.135,24.942 L8.395,26.21 L9.38,23.119 L7.467,25.149 C7.728,26.571 8.314,27.883 9.147,28.997 L9.147,28.997 L7.45,28.997 C6.957,28.189 6.571,27.312 6.305,26.382 L6.305,26.382 L5,27.769 L5.0005667,25.4970384 C5.01020062,22.6453117 5.18361111,19.2052778 8.305,16.048 C9.379,14.965 10.619,14.126 11.965,13.564 C11.633,12.878 11.495,12.098 11.56,11.258 L11.56,11.258 L10.558,11.197 C9.53,11.133 8.742,10.247 8.803,9.218 L8.803,9.218 L8.803,9.215 L8.891,7.813 C8.951,6.829 9.771,6.058 10.761,6.058 C10.795,6.058 10.832,6.058 10.865,6.061 L10.865,6.061 L10.877,6.061 L12.273,6.147 C12.752,6.175 13.19,6.382 13.518,6.727 C13.815,6.294 14.133,5.854 14.463,5.399 L14.463,5.399 L14.75,5 Z M19.493,25.417 C20.019,25.417 20.447,25.848 20.447,26.372 L20.451,26.371 C20.451,26.899 20.023,27.324 19.496,27.324 C18.97,27.324 18.544,26.899 18.544,26.371 C18.544,25.845 18.967,25.417 19.493,25.417 Z M12.981,11.191 C13.104,10.189 13.559,9.242 14.211,8.221 C14.236,8.271 14.265,8.318 14.295,8.365 C14.559,8.763 15.008,8.99 15.494,8.97 C15.711,8.962 16.099,8.995 16.727,9.202 C17.441,9.438 18.013,9.946 18.335,10.627 C18.657,11.308 18.684,12.069 18.414,12.776 C18.241,13.221 17.96,13.596 17.608,13.885 L17.2,13.383 L17.198,13.38 C16.919,13.039 16.504,12.845 16.064,12.845 C15.729,12.845 15.4,12.962 15.139,13.175 C14.805,13.445 14.625,13.835 14.605,14.233 C13.405,13.692 12.805,12.59 12.977,11.192 L12.981,11.191 L12.981,11.191 Z M17.285,16.301 L16.766,16.726 C16.72,16.762 16.671,16.779 16.62,16.779 C16.554,16.779 16.487,16.749 16.443,16.694 L16.332,16.559 C16.249,16.459 16.265,16.309 16.366,16.225 L16.876,15.805 L15.821,14.506 C15.712,14.373 15.73,14.176 15.865,14.07 C15.923,14.022 15.991,13.998 16.059,13.998 C16.15,13.998 16.24,14.036 16.299,14.111 L19.262,17.756 C19.371,17.891 19.352,18.086 19.22,18.192 C19.181,18.221 19.138,18.245 19.094,18.255 C19.071,18.261 19.049,18.264 19.024,18.264 C18.934,18.264 18.846,18.224 18.784,18.151 L18.489,17.786 L17.444,18.64 C17.398,18.677 17.344,18.695 17.29,18.695 C17.222,18.695 17.151,18.665 17.104,18.605 L16.627,18.026 C16.545,17.924 16.559,17.774 16.662,17.69 L17.713,16.833 L17.287,16.3 L17.285,16.301 L17.285,16.301 Z M11.84,9.866 L10.644,9.791 C10.389,9.776 10.194,9.556 10.209,9.303 L10.299,7.902 C10.313,7.657 10.515,7.466 10.76,7.466 L10.784,7.466 L12.185,7.557 C12.308,7.563 12.421,7.617 12.502,7.709 C12.585,7.803 12.625,7.919 12.618,8.045 L12.611,8.146 C12.291,8.713 12.026,9.28 11.838,9.866 L11.84,9.866 L11.84,9.866 Z M24.364,21.347 C23.799,22.152 22.677,22.428 21.44,22.065 C17.554,20.924 14.044,21.162 10.972,22.766 L12.608,17.643 L7.317,23.252 C7.416,19.49 9.77,16.286 13.075,14.941 C13.546,15.314 14.109,15.601 14.748,15.782 C14.908,15.826 15.07,15.856 15.228,15.884 C15.045,16.342 15.109,16.881 15.438,17.291 L15.513,17.381 C15.341,17.831 15.408,18.356 15.734,18.755 L16.209,19.337 C16.475,19.662 16.868,19.85 17.288,19.85 C17.609,19.85 17.923,19.739 18.174,19.536 L18.459,19.304 C18.633,19.378 18.826,19.417 19.025,19.417 C19.138,19.417 19.247,19.407 19.355,19.382 C19.573,19.332 19.779,19.232 19.953,19.091 C20.576,18.581 20.673,17.656 20.162,17.031 L18.492,14.975 C18.637,14.858 18.773,14.731 18.9,14.594 C19.035,14.631 19.171,14.672 19.3,14.714 C19.566,14.811 19.833,14.912 20.095,15.029 C21.1,15.474 22.049,16.129 22.866,16.926 C22.895,16.956 22.925,16.981 22.951,17.009 L23.121,17.184 C23.159,17.223 23.197,17.263 23.232,17.304 C23.311,17.389 23.392,17.479 23.471,17.571 L23.597,17.721 C23.642,17.774 23.683,17.825 23.727,17.881 L23.841,18.031 C23.881,18.082 23.92,18.133 23.958,18.185 C24.796,19.334 24.945,20.514 24.362,21.342 L24.362,21.347 L24.364,21.347 Z M11.806,9.115 L10.971,9.064 L11.024,8.229 L11.858,8.28 L11.806,9.115 Z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>




</div>
  </div>
</footer>

    

  <script src="/dist/js/app.3fc0f988d21662902933.js"></script>


  </body>
</html>
